2021-06-03 14:51:54,525 args = Namespace(arch_learning_rate=0.0003, arch_weight_decay=0.001, batch_size=64, ckpt_interval=20, cutout=False, cutout_length=16, cutout_prob=1.0, data='../data', dataset='cifar10', dev='proj', edge_decision='random', epochs=100, expid_tag='none', fast=False, gpu='auto', grad_clip=5, init_channels=16, layers=8, learning_rate=0.025, learning_rate_min=0.001, log_tag='', method='darts-proj', model_path='saved_models', momentum=0.9, proj_crit='acc', proj_intv=5, report_freq=50, resume_epoch=100, resume_expid='search-darts-201-0', save='../experiments/nasbench201/search-darts-201-0', search_space='nas-bench-201', seed=0, train_portion=0.5, weight_decay=0.0003)
2021-06-03 14:51:54,525 gpu device = 0
2021-06-03 14:52:08,281 param size = 1.686106MB
2021-06-03 14:52:09,260 loading checkpoint from darts-proj-201
2021-06-03 14:52:09,260 => loading checkpoint '../experiments/nasbench201/search-darts-201-0/checkpoint_100.pth.tar'
2021-06-03 14:52:09,673 => loaded checkpoint '../experiments/nasbench201/search-darts-201-0/checkpoint_100.pth.tar' (epoch 99)
2021-06-03 14:52:22,587 tensor([[0.0674, 0.7638, 0.0531, 0.0862, 0.0296],
        [0.0588, 0.8147, 0.0436, 0.0514, 0.0315],
        [0.4450, 0.3992, 0.0407, 0.0588, 0.0563],
        [0.0228, 0.8049, 0.0603, 0.0931, 0.0189],
        [0.0587, 0.8135, 0.0542, 0.0442, 0.0295],
        [0.2168, 0.6368, 0.0586, 0.0566, 0.0311]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 14:52:41,552 train_acc  96.335999
2021-06-03 14:52:41,553 train_loss 0.118453
2021-06-03 14:52:59,912 valid_acc  86.799995
2021-06-03 14:52:59,912 valid_loss 0.413486
2021-06-03 14:52:59,916 epoch 0
2021-06-03 14:52:59,916 project
2021-06-03 14:53:20,094 valid_acc 85.636002
2021-06-03 14:53:20,094 valid_loss 0.447464
2021-06-03 14:53:40,190 valid_acc 12.372000
2021-06-03 14:53:40,190 valid_loss 6.707353
2021-06-03 14:53:59,985 valid_acc 76.888000
2021-06-03 14:53:59,986 valid_loss 0.724353
2021-06-03 14:54:20,199 valid_acc 57.067997
2021-06-03 14:54:20,199 valid_loss 1.457087
2021-06-03 14:54:40,032 valid_acc 85.748001
2021-06-03 14:54:40,032 valid_loss 0.446578
2021-06-03 14:55:00,093 valid_acc 85.643997
2021-06-03 14:55:00,093 valid_loss 0.448759
2021-06-03 14:55:20,237 valid_acc 32.804001
2021-06-03 14:55:20,237 valid_loss 3.542422
2021-06-03 14:55:40,477 valid_acc 83.283997
2021-06-03 14:55:40,477 valid_loss 0.519764
2021-06-03 14:56:00,411 valid_acc 80.304001
2021-06-03 14:56:00,411 valid_loss 0.611404
2021-06-03 14:56:20,467 valid_acc 85.855995
2021-06-03 14:56:20,467 valid_loss 0.445455
2021-06-03 14:56:40,927 valid_acc 85.559998
2021-06-03 14:56:40,927 valid_loss 0.448925
2021-06-03 14:57:01,233 valid_acc 82.792000
2021-06-03 14:57:01,234 valid_loss 0.594802
2021-06-03 14:57:21,303 valid_acc 83.916000
2021-06-03 14:57:21,303 valid_loss 0.492400
2021-06-03 14:57:41,464 valid_acc 79.503998
2021-06-03 14:57:41,464 valid_loss 0.644457
2021-06-03 14:58:01,615 valid_acc 85.720001
2021-06-03 14:58:01,615 valid_loss 0.446936
2021-06-03 14:58:21,823 valid_acc 85.807999
2021-06-03 14:58:21,824 valid_loss 0.441658
2021-06-03 14:58:41,838 valid_acc 10.875999
2021-06-03 14:58:41,838 valid_loss 6.412320
2021-06-03 14:59:02,093 valid_acc 77.279999
2021-06-03 14:59:02,093 valid_loss 0.724004
2021-06-03 14:59:22,382 valid_acc 55.267998
2021-06-03 14:59:22,383 valid_loss 1.468830
2021-06-03 14:59:42,605 valid_acc 85.607994
2021-06-03 14:59:42,605 valid_loss 0.451349
2021-06-03 15:00:02,801 valid_acc 85.391998
2021-06-03 15:00:02,802 valid_loss 0.449243
2021-06-03 15:00:22,992 valid_acc 49.995998
2021-06-03 15:00:22,992 valid_loss 2.344997
2021-06-03 15:00:43,226 valid_acc 79.587997
2021-06-03 15:00:43,226 valid_loss 0.627744
2021-06-03 15:01:03,632 valid_acc 79.783997
2021-06-03 15:01:03,632 valid_loss 0.630134
2021-06-03 15:01:23,496 valid_acc 85.568001
2021-06-03 15:01:23,496 valid_loss 0.453362
2021-06-03 15:01:43,813 valid_acc 85.671997
2021-06-03 15:01:43,814 valid_loss 0.443916
2021-06-03 15:02:03,996 valid_acc 45.335999
2021-06-03 15:02:03,996 valid_loss 2.842211
2021-06-03 15:02:24,244 valid_acc 77.835999
2021-06-03 15:02:24,244 valid_loss 0.688150
2021-06-03 15:02:44,372 valid_acc 72.776001
2021-06-03 15:02:44,372 valid_loss 0.858677
2021-06-03 15:03:04,715 valid_acc 85.743996
2021-06-03 15:03:04,715 valid_loss 0.440518
2021-06-03 15:04:44,846 best opid 1
2021-06-03 15:04:44,846 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0588, 0.8147, 0.0436, 0.0514, 0.0315],
        [0.4450, 0.3992, 0.0407, 0.0588, 0.0563],
        [0.0228, 0.8049, 0.0603, 0.0931, 0.0189],
        [0.0587, 0.8135, 0.0542, 0.0442, 0.0295],
        [0.2168, 0.6368, 0.0586, 0.0566, 0.0311]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:04:45,334 train 000 2.233607e+00 25.000000 81.250000
2021-06-03 15:05:01,213 train 050 1.668838e+00 40.870098 88.817406
2021-06-03 15:05:17,533 train 100 1.530347e+00 45.668316 90.965347
2021-06-03 15:05:33,437 train 150 1.421716e+00 49.358444 92.508278
2021-06-03 15:05:49,075 train 200 1.325698e+00 52.899563 93.462372
2021-06-03 15:06:05,469 train 250 1.244480e+00 55.888947 94.216888
2021-06-03 15:06:21,227 train 300 1.183482e+00 58.113579 94.819351
2021-06-03 15:06:37,715 train 350 1.124935e+00 60.278667 95.325851
2021-06-03 15:06:50,709 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0757, 0.7798, 0.0505, 0.0603, 0.0338],
        [0.5185, 0.3319, 0.0411, 0.0597, 0.0488],
        [0.0283, 0.7854, 0.0648, 0.1010, 0.0204],
        [0.0790, 0.7843, 0.0580, 0.0468, 0.0320],
        [0.2737, 0.5666, 0.0653, 0.0644, 0.0299]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:07:09,142 train_acc  73.459999
2021-06-03 15:07:09,142 train_loss 0.757978
2021-06-03 15:07:27,631 valid_acc  71.255997
2021-06-03 15:07:27,631 valid_loss 0.830100
2021-06-03 15:07:27,631 epoch 1
2021-06-03 15:07:27,994 train 000 1.086104e+00 61.813759 95.643158
2021-06-03 15:07:43,860 train 050 1.049402e+00 63.161621 95.863998
2021-06-03 15:08:00,434 train 100 1.014060e+00 64.406944 96.132088
2021-06-03 15:08:16,285 train 150 9.854223e-01 65.477150 96.350685
2021-06-03 15:08:32,087 train 200 9.598291e-01 66.437775 96.548172
2021-06-03 15:08:48,533 train 250 9.360453e-01 67.338783 96.702705
2021-06-03 15:09:04,439 train 300 9.120019e-01 68.184082 96.868790
2021-06-03 15:09:20,916 train 350 8.905399e-01 68.932243 96.997726
2021-06-03 15:09:33,940 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0860, 0.7595, 0.0542, 0.0658, 0.0345],
        [0.5515, 0.3035, 0.0406, 0.0596, 0.0448],
        [0.0322, 0.7696, 0.0694, 0.1075, 0.0213],
        [0.0911, 0.7669, 0.0607, 0.0482, 0.0330],
        [0.3036, 0.5316, 0.0682, 0.0680, 0.0287]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:09:52,685 train_acc  81.068001
2021-06-03 15:09:52,686 train_loss 0.544807
2021-06-03 15:10:11,342 valid_acc  77.495995
2021-06-03 15:10:11,342 valid_loss 0.656787
2021-06-03 15:10:11,342 epoch 2
2021-06-03 15:10:11,683 train 000 8.727596e-01 69.586929 97.101715
2021-06-03 15:10:27,415 train 050 8.539474e-01 70.235054 97.219505
2021-06-03 15:10:43,917 train 100 8.389632e-01 70.731796 97.325729
2021-06-03 15:10:59,708 train 150 8.248596e-01 71.248993 97.417198
2021-06-03 15:11:15,698 train 200 8.097348e-01 71.791481 97.510498
2021-06-03 15:11:32,109 train 250 7.969518e-01 72.226929 97.582642
2021-06-03 15:11:47,658 train 300 7.836639e-01 72.707321 97.656792
2021-06-03 15:12:03,937 train 350 7.737677e-01 73.070770 97.732666
2021-06-03 15:12:16,673 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0942, 0.7454, 0.0563, 0.0694, 0.0348],
        [0.5745, 0.2849, 0.0398, 0.0589, 0.0420],
        [0.0357, 0.7587, 0.0716, 0.1123, 0.0216],
        [0.1017, 0.7528, 0.0626, 0.0498, 0.0331],
        [0.3271, 0.5059, 0.0692, 0.0703, 0.0275]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:12:34,160 train_acc  83.047997
2021-06-03 15:12:34,160 train_loss 0.486089
2021-06-03 15:12:52,059 valid_acc  78.916000
2021-06-03 15:12:52,059 valid_loss 0.622641
2021-06-03 15:12:52,059 epoch 3
2021-06-03 15:12:52,396 train 000 7.641035e-01 73.396034 97.789886
2021-06-03 15:13:08,079 train 050 7.531751e-01 73.781044 97.848305
2021-06-03 15:13:24,254 train 100 7.428763e-01 74.143181 97.908279
2021-06-03 15:13:39,861 train 150 7.329260e-01 74.496834 97.951904
2021-06-03 15:13:55,520 train 200 7.232508e-01 74.825867 97.998047
2021-06-03 15:14:11,700 train 250 7.157559e-01 75.075775 98.044235
2021-06-03 15:14:27,335 train 300 7.075173e-01 75.363869 98.085159
2021-06-03 15:14:43,461 train 350 7.000309e-01 75.602272 98.122383
2021-06-03 15:14:56,191 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1003, 0.7356, 0.0577, 0.0717, 0.0347],
        [0.5914, 0.2721, 0.0392, 0.0574, 0.0399],
        [0.0383, 0.7506, 0.0737, 0.1156, 0.0217],
        [0.1094, 0.7444, 0.0635, 0.0502, 0.0326],
        [0.3453, 0.4870, 0.0699, 0.0715, 0.0263]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:15:13,907 train_acc  86.211998
2021-06-03 15:15:13,907 train_loss 0.394904
2021-06-03 15:15:32,020 valid_acc  81.647995
2021-06-03 15:15:32,020 valid_loss 0.547549
2021-06-03 15:15:32,020 epoch 4
2021-06-03 15:15:32,371 train 000 6.938158e-01 75.804489 98.151184
2021-06-03 15:15:48,118 train 050 6.856999e-01 76.093315 98.188133
2021-06-03 15:16:04,436 train 100 6.787433e-01 76.329086 98.223816
2021-06-03 15:16:20,359 train 150 6.728370e-01 76.541077 98.255585
2021-06-03 15:16:36,265 train 200 6.661122e-01 76.774704 98.292633
2021-06-03 15:16:52,447 train 250 6.599346e-01 76.968742 98.322479
2021-06-03 15:17:08,238 train 300 6.538898e-01 77.168297 98.354912
2021-06-03 15:17:24,663 train 350 6.480362e-01 77.360695 98.383202
2021-06-03 15:17:37,555 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1051, 0.7288, 0.0583, 0.0735, 0.0342],
        [0.6038, 0.2631, 0.0386, 0.0565, 0.0381],
        [0.0404, 0.7454, 0.0749, 0.1177, 0.0217],
        [0.1151, 0.7390, 0.0638, 0.0501, 0.0320],
        [0.3595, 0.4724, 0.0702, 0.0724, 0.0255]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:17:55,873 train_acc  86.715996
2021-06-03 15:17:55,873 train_loss 0.385300
2021-06-03 15:18:14,076 valid_acc  81.919998
2021-06-03 15:18:14,076 valid_loss 0.549882
2021-06-03 15:18:14,077 epoch 5
2021-06-03 15:18:14,077 project
2021-06-03 15:18:34,491 valid_acc 81.028000
2021-06-03 15:18:34,491 valid_loss 0.560780
2021-06-03 15:18:55,062 valid_acc 46.691998
2021-06-03 15:18:55,062 valid_loss 2.306470
2021-06-03 15:19:15,612 valid_acc 77.711998
2021-06-03 15:19:15,612 valid_loss 0.670278
2021-06-03 15:19:36,024 valid_acc 71.615997
2021-06-03 15:19:36,024 valid_loss 0.847286
2021-06-03 15:19:56,131 valid_acc 81.419998
2021-06-03 15:19:56,131 valid_loss 0.558567
2021-06-03 15:20:16,220 valid_acc 81.335999
2021-06-03 15:20:16,220 valid_loss 0.559276
2021-06-03 15:20:36,227 valid_acc 78.307999
2021-06-03 15:20:36,227 valid_loss 0.697193
2021-06-03 15:20:56,246 valid_acc 80.167999
2021-06-03 15:20:56,246 valid_loss 0.596198
2021-06-03 15:21:16,230 valid_acc 77.103996
2021-06-03 15:21:16,230 valid_loss 0.684263
2021-06-03 15:21:36,811 valid_acc 81.267998
2021-06-03 15:21:36,811 valid_loss 0.561640
2021-06-03 15:21:56,811 valid_acc 81.075996
2021-06-03 15:21:56,811 valid_loss 0.564746
2021-06-03 15:22:17,108 valid_acc 12.427999
2021-06-03 15:22:17,108 valid_loss 6.191768
2021-06-03 15:22:37,107 valid_acc 71.423996
2021-06-03 15:22:37,107 valid_loss 0.867992
2021-06-03 15:22:57,139 valid_acc 40.112000
2021-06-03 15:22:57,139 valid_loss 1.912861
2021-06-03 15:23:17,391 valid_acc 81.307999
2021-06-03 15:23:17,392 valid_loss 0.559020
2021-06-03 15:23:37,841 valid_acc 81.400002
2021-06-03 15:23:37,841 valid_loss 0.558457
2021-06-03 15:23:57,835 valid_acc 12.575999
2021-06-03 15:23:57,835 valid_loss 6.142189
2021-06-03 15:24:17,975 valid_acc 70.984001
2021-06-03 15:24:17,975 valid_loss 0.864942
2021-06-03 15:24:38,171 valid_acc 73.939995
2021-06-03 15:24:38,171 valid_loss 0.791672
2021-06-03 15:24:58,157 valid_acc 81.187996
2021-06-03 15:24:58,157 valid_loss 0.562319
2021-06-03 15:25:18,361 valid_acc 81.071999
2021-06-03 15:25:18,361 valid_loss 0.566104
2021-06-03 15:25:38,586 valid_acc 61.119999
2021-06-03 15:25:38,587 valid_loss 1.614502
2021-06-03 15:25:58,814 valid_acc 70.675995
2021-06-03 15:25:58,814 valid_loss 0.859397
2021-06-03 15:26:19,165 valid_acc 58.396000
2021-06-03 15:26:19,165 valid_loss 1.288509
2021-06-03 15:26:39,266 valid_acc 81.512001
2021-06-03 15:26:39,266 valid_loss 0.556925
2021-06-03 15:28:26,250 best opid 1
2021-06-03 15:28:26,250 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.6038, 0.2631, 0.0386, 0.0565, 0.0381],
        [0.0404, 0.7454, 0.0749, 0.1177, 0.0217],
        [0.1151, 0.7390, 0.0638, 0.0501, 0.0320],
        [0.3595, 0.4724, 0.0702, 0.0724, 0.0255]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:28:26,592 train 000 6.438669e-01 77.502724 98.407219
2021-06-03 15:28:42,878 train 050 6.509799e-01 77.264854 98.375999
2021-06-03 15:28:58,769 train 100 6.530390e-01 77.202888 98.369141
2021-06-03 15:29:15,040 train 150 6.540703e-01 77.163902 98.375961
2021-06-03 15:29:30,856 train 200 6.538656e-01 77.182587 98.384644
2021-06-03 15:29:46,809 train 250 6.534134e-01 77.190498 98.398598
2021-06-03 15:30:03,661 train 300 6.526260e-01 77.212608 98.407776
2021-06-03 15:30:19,732 train 350 6.513765e-01 77.292084 98.407745
2021-06-03 15:30:32,844 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.6003, 0.2489, 0.0455, 0.0695, 0.0359],
        [0.0456, 0.7331, 0.0766, 0.1222, 0.0225],
        [0.1315, 0.7184, 0.0661, 0.0515, 0.0326],
        [0.4014, 0.4318, 0.0699, 0.0728, 0.0240]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:30:51,325 train_acc  81.320000
2021-06-03 15:30:51,325 train_loss 0.539375
2021-06-03 15:31:09,947 valid_acc  78.292000
2021-06-03 15:31:09,948 valid_loss 0.648949
2021-06-03 15:31:09,948 epoch 6
2021-06-03 15:31:10,309 train 000 6.501329e-01 77.341003 98.417343
2021-06-03 15:31:26,949 train 050 6.476173e-01 77.445457 98.439293
2021-06-03 15:31:42,917 train 100 6.458018e-01 77.497704 98.455238
2021-06-03 15:31:59,386 train 150 6.430424e-01 77.575409 98.473038
2021-06-03 15:32:15,534 train 200 6.417341e-01 77.624893 98.489540
2021-06-03 15:32:31,618 train 250 6.393564e-01 77.723648 98.503593
2021-06-03 15:32:48,038 train 300 6.368618e-01 77.806267 98.515923
2021-06-03 15:33:04,094 train 350 6.346719e-01 77.880600 98.530128
2021-06-03 15:33:16,915 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5984, 0.2412, 0.0494, 0.0762, 0.0348],
        [0.0491, 0.7250, 0.0772, 0.1259, 0.0228],
        [0.1419, 0.7081, 0.0661, 0.0514, 0.0325],
        [0.4257, 0.4086, 0.0701, 0.0727, 0.0229]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:33:34,627 train_acc  83.695999
2021-06-03 15:33:34,627 train_loss 0.469024
2021-06-03 15:33:52,300 valid_acc  79.675995
2021-06-03 15:33:52,301 valid_loss 0.598099
2021-06-03 15:33:52,301 epoch 7
2021-06-03 15:33:52,637 train 000 6.326861e-01 77.954346 98.541672
2021-06-03 15:34:08,893 train 050 6.301432e-01 78.038185 98.553825
2021-06-03 15:34:24,410 train 100 6.279064e-01 78.121826 98.564453
2021-06-03 15:34:40,669 train 150 6.257720e-01 78.192284 98.580124
2021-06-03 15:34:56,481 train 200 6.234826e-01 78.276840 98.593666
2021-06-03 15:35:12,158 train 250 6.205832e-01 78.374260 98.608841
2021-06-03 15:35:28,343 train 300 6.189106e-01 78.438103 98.617340
2021-06-03 15:35:44,166 train 350 6.164847e-01 78.525200 98.628105
2021-06-03 15:35:56,777 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5962, 0.2353, 0.0521, 0.0825, 0.0340],
        [0.0522, 0.7180, 0.0784, 0.1285, 0.0230],
        [0.1512, 0.6980, 0.0668, 0.0519, 0.0322],
        [0.4450, 0.3905, 0.0700, 0.0725, 0.0220]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:36:14,752 train_acc  85.271996
2021-06-03 15:36:14,752 train_loss 0.419178
2021-06-03 15:36:32,758 valid_acc  81.211998
2021-06-03 15:36:32,758 valid_loss 0.561469
2021-06-03 15:36:32,758 epoch 8
2021-06-03 15:36:33,096 train 000 6.145290e-01 78.591850 98.638435
2021-06-03 15:36:49,234 train 050 6.122253e-01 78.673050 98.649536
2021-06-03 15:37:05,117 train 100 6.101362e-01 78.752228 98.655945
2021-06-03 15:37:21,635 train 150 6.076030e-01 78.836617 98.669304
2021-06-03 15:37:37,587 train 200 6.051225e-01 78.927864 98.679909
2021-06-03 15:37:53,533 train 250 6.026957e-01 79.014557 98.689278
2021-06-03 15:38:09,711 train 300 6.004323e-01 79.095062 98.702934
2021-06-03 15:38:25,313 train 350 5.980636e-01 79.185844 98.715302
2021-06-03 15:38:38,103 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5936, 0.2322, 0.0544, 0.0863, 0.0335],
        [0.0537, 0.7161, 0.0780, 0.1292, 0.0230],
        [0.1555, 0.6953, 0.0659, 0.0516, 0.0317],
        [0.4572, 0.3812, 0.0686, 0.0716, 0.0214]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:38:56,354 train_acc  86.708000
2021-06-03 15:38:56,355 train_loss 0.382661
2021-06-03 15:39:14,605 valid_acc  82.071999
2021-06-03 15:39:14,606 valid_loss 0.533386
2021-06-03 15:39:14,606 epoch 9
2021-06-03 15:39:14,945 train 000 5.959421e-01 79.257004 98.723915
2021-06-03 15:39:31,546 train 050 5.934954e-01 79.342339 98.733047
2021-06-03 15:39:47,707 train 100 5.917054e-01 79.407600 98.740623
2021-06-03 15:40:04,469 train 150 5.891865e-01 79.491951 98.752686
2021-06-03 15:40:20,237 train 200 5.873162e-01 79.556381 98.760635
2021-06-03 15:40:35,977 train 250 5.852646e-01 79.626984 98.770447
2021-06-03 15:40:52,384 train 300 5.832704e-01 79.690826 98.782463
2021-06-03 15:41:08,011 train 350 5.810456e-01 79.769585 98.792549
2021-06-03 15:41:20,904 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5870, 0.2292, 0.0573, 0.0933, 0.0332],
        [0.0552, 0.7130, 0.0790, 0.1296, 0.0231],
        [0.1599, 0.6940, 0.0646, 0.0500, 0.0316],
        [0.4683, 0.3721, 0.0677, 0.0709, 0.0210]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:41:39,291 train_acc  86.579994
2021-06-03 15:41:39,291 train_loss 0.380511
2021-06-03 15:41:57,003 valid_acc  81.863998
2021-06-03 15:41:57,003 valid_loss 0.545448
2021-06-03 15:41:57,003 epoch 10
2021-06-03 15:41:57,003 project
2021-06-03 15:42:16,933 valid_acc 80.811996
2021-06-03 15:42:16,933 valid_loss 0.574141
2021-06-03 15:42:36,824 valid_acc 80.152000
2021-06-03 15:42:36,824 valid_loss 0.614429
2021-06-03 15:42:56,488 valid_acc 78.888000
2021-06-03 15:42:56,488 valid_loss 0.620968
2021-06-03 15:43:16,825 valid_acc 68.667999
2021-06-03 15:43:16,825 valid_loss 0.945951
2021-06-03 15:43:37,170 valid_acc 80.875999
2021-06-03 15:43:37,170 valid_loss 0.569384
2021-06-03 15:43:56,951 valid_acc 80.851997
2021-06-03 15:43:56,951 valid_loss 0.572693
2021-06-03 15:44:16,697 valid_acc 11.384000
2021-06-03 15:44:16,697 valid_loss 6.104821
2021-06-03 15:44:36,435 valid_acc 70.012001
2021-06-03 15:44:36,435 valid_loss 0.887698
2021-06-03 15:44:55,966 valid_acc 28.983999
2021-06-03 15:44:55,967 valid_loss 2.292124
2021-06-03 15:45:16,309 valid_acc 80.652000
2021-06-03 15:45:16,309 valid_loss 0.571988
2021-06-03 15:45:38,831 valid_acc 80.695999
2021-06-03 15:45:38,831 valid_loss 0.566133
2021-06-03 15:46:02,821 valid_acc 11.564000
2021-06-03 15:46:02,822 valid_loss 5.979475
2021-06-03 15:46:22,109 valid_acc 73.447998
2021-06-03 15:46:22,109 valid_loss 0.786556
2021-06-03 15:46:42,277 valid_acc 75.019997
2021-06-03 15:46:42,277 valid_loss 0.741619
2021-06-03 15:47:02,321 valid_acc 80.956001
2021-06-03 15:47:02,321 valid_loss 0.564826
2021-06-03 15:47:21,933 valid_acc 80.820000
2021-06-03 15:47:21,933 valid_loss 0.568215
2021-06-03 15:47:41,975 valid_acc 54.711998
2021-06-03 15:47:41,975 valid_loss 1.870772
2021-06-03 15:48:01,949 valid_acc 73.664001
2021-06-03 15:48:01,949 valid_loss 0.775626
2021-06-03 15:48:21,520 valid_acc 59.556000
2021-06-03 15:48:21,520 valid_loss 1.222689
2021-06-03 15:48:41,337 valid_acc 80.928001
2021-06-03 15:48:41,338 valid_loss 0.568238
2021-06-03 15:50:19,475 best opid 3
2021-06-03 15:50:19,475 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0552, 0.7130, 0.0790, 0.1296, 0.0231],
        [0.1599, 0.6940, 0.0646, 0.0500, 0.0316],
        [0.4683, 0.3721, 0.0677, 0.0709, 0.0210]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:50:19,830 train 000 5.807202e-01 79.806770 98.787109
2021-06-03 15:50:35,442 train 050 6.038456e-01 79.132446 98.534729
2021-06-03 15:50:50,967 train 100 6.154228e-01 78.702278 98.440720
2021-06-03 15:51:07,149 train 150 6.241004e-01 78.388611 98.388306
2021-06-03 15:51:22,691 train 200 6.296186e-01 78.195190 98.363411
2021-06-03 15:51:38,846 train 250 6.337852e-01 78.048515 98.345886
2021-06-03 15:51:54,564 train 300 6.363524e-01 77.955093 98.339546
2021-06-03 15:52:10,735 train 350 6.381357e-01 77.882584 98.338501
2021-06-03 15:52:22,926 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0556, 0.7044, 0.0807, 0.1363, 0.0230],
        [0.1601, 0.6935, 0.0651, 0.0502, 0.0312],
        [0.4879, 0.3494, 0.0702, 0.0728, 0.0197]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:52:40,686 train_acc  75.751999
2021-06-03 15:52:40,686 train_loss 0.700643
2021-06-03 15:52:59,103 valid_acc  73.411995
2021-06-03 15:52:59,104 valid_loss 0.758249
2021-06-03 15:52:59,104 epoch 11
2021-06-03 15:52:59,435 train 000 6.395962e-01 77.828064 98.333839
2021-06-03 15:53:15,002 train 050 6.401120e-01 77.819267 98.334320
2021-06-03 15:53:30,471 train 100 6.405321e-01 77.804268 98.337616
2021-06-03 15:53:46,857 train 150 6.405237e-01 77.805763 98.344368
2021-06-03 15:54:02,720 train 200 6.402780e-01 77.812439 98.350960
2021-06-03 15:54:19,080 train 250 6.398539e-01 77.829964 98.353630
2021-06-03 15:54:35,057 train 300 6.392320e-01 77.849823 98.360992
2021-06-03 15:54:51,555 train 350 6.381792e-01 77.889091 98.371567
2021-06-03 15:55:03,871 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0566, 0.6941, 0.0830, 0.1429, 0.0234],
        [0.1625, 0.6887, 0.0665, 0.0507, 0.0316],
        [0.5041, 0.3296, 0.0725, 0.0747, 0.0190]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:55:22,307 train_acc  81.603996
2021-06-03 15:55:22,308 train_loss 0.524639
2021-06-03 15:55:40,168 valid_acc  78.736000
2021-06-03 15:55:40,168 valid_loss 0.617625
2021-06-03 15:55:40,168 epoch 12
2021-06-03 15:55:40,503 train 000 6.375708e-01 77.909714 98.380013
2021-06-03 15:55:56,352 train 050 6.358886e-01 77.970345 98.390182
2021-06-03 15:56:12,716 train 100 6.344094e-01 78.025803 98.400467
2021-06-03 15:56:28,638 train 150 6.332600e-01 78.064934 98.409569
2021-06-03 15:56:44,627 train 200 6.322560e-01 78.087288 98.417847
2021-06-03 15:57:01,097 train 250 6.311328e-01 78.128159 98.422470
2021-06-03 15:57:17,163 train 300 6.295102e-01 78.179497 98.431702
2021-06-03 15:57:34,726 train 350 6.280666e-01 78.233849 98.441994
2021-06-03 15:57:48,443 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0564, 0.6896, 0.0840, 0.1466, 0.0235],
        [0.1613, 0.6908, 0.0662, 0.0501, 0.0316],
        [0.5136, 0.3187, 0.0734, 0.0757, 0.0187]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 15:58:09,603 train_acc  85.928001
2021-06-03 15:58:09,603 train_loss 0.404431
2021-06-03 15:58:28,051 valid_acc  82.003998
2021-06-03 15:58:28,051 valid_loss 0.528805
2021-06-03 15:58:28,051 epoch 13
2021-06-03 15:58:28,395 train 000 6.266974e-01 78.278122 98.449532
2021-06-03 15:58:44,254 train 050 6.249599e-01 78.336952 98.459778
2021-06-03 15:59:00,588 train 100 6.231517e-01 78.397057 98.470123
2021-06-03 15:59:16,523 train 150 6.213341e-01 78.459290 98.480270
2021-06-03 15:59:32,410 train 200 6.197182e-01 78.513550 98.487854
2021-06-03 15:59:48,886 train 250 6.181892e-01 78.564438 98.497353
2021-06-03 16:00:04,862 train 300 6.164502e-01 78.630646 98.506966
2021-06-03 16:00:21,449 train 350 6.147599e-01 78.687576 98.513802
2021-06-03 16:00:33,803 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0562, 0.6873, 0.0848, 0.1482, 0.0235],
        [0.1602, 0.6919, 0.0664, 0.0501, 0.0314],
        [0.5203, 0.3105, 0.0744, 0.0764, 0.0184]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:00:52,712 train_acc  87.400002
2021-06-03 16:00:52,712 train_loss 0.362867
2021-06-03 16:01:11,635 valid_acc  82.563995
2021-06-03 16:01:11,635 valid_loss 0.514179
2021-06-03 16:01:11,635 epoch 14
2021-06-03 16:01:11,975 train 000 6.135014e-01 78.728180 98.521416
2021-06-03 16:01:27,990 train 050 6.114523e-01 78.794609 98.530838
2021-06-03 16:01:44,431 train 100 6.096503e-01 78.857330 98.539261
2021-06-03 16:02:00,369 train 150 6.078467e-01 78.920052 98.550316
2021-06-03 16:02:16,108 train 200 6.060207e-01 78.985245 98.559242
2021-06-03 16:02:32,540 train 250 6.042017e-01 79.048744 98.566917
2021-06-03 16:02:48,459 train 300 6.025871e-01 79.105461 98.574463
2021-06-03 16:03:05,023 train 350 6.008294e-01 79.167381 98.582947
2021-06-03 16:03:18,195 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0547, 0.6885, 0.0841, 0.1493, 0.0234],
        [0.1550, 0.7001, 0.0651, 0.0487, 0.0311],
        [0.5260, 0.3048, 0.0744, 0.0766, 0.0182]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:03:36,869 train_acc  87.715996
2021-06-03 16:03:36,869 train_loss 0.350755
2021-06-03 16:03:55,850 valid_acc  82.579994
2021-06-03 16:03:55,851 valid_loss 0.516661
2021-06-03 16:03:55,851 epoch 15
2021-06-03 16:03:55,851 project
2021-06-03 16:04:16,454 valid_acc 82.035995
2021-06-03 16:04:16,455 valid_loss 0.534884
2021-06-03 16:04:37,214 valid_acc 10.731999
2021-06-03 16:04:37,214 valid_loss 6.783197
2021-06-03 16:04:57,567 valid_acc 77.832001
2021-06-03 16:04:57,567 valid_loss 0.648729
2021-06-03 16:05:17,598 valid_acc 62.368000
2021-06-03 16:05:17,599 valid_loss 1.141598
2021-06-03 16:05:37,725 valid_acc 82.152000
2021-06-03 16:05:37,725 valid_loss 0.530308
2021-06-03 16:05:57,926 valid_acc 82.283997
2021-06-03 16:05:57,926 valid_loss 0.532443
2021-06-03 16:06:18,885 valid_acc 10.731999
2021-06-03 16:06:18,885 valid_loss 6.804630
2021-06-03 16:06:39,985 valid_acc 79.428001
2021-06-03 16:06:39,986 valid_loss 0.610161
2021-06-03 16:07:00,258 valid_acc 80.315994
2021-06-03 16:07:00,258 valid_loss 0.581846
2021-06-03 16:07:20,376 valid_acc 82.099998
2021-06-03 16:07:20,377 valid_loss 0.537068
2021-06-03 16:07:40,540 valid_acc 81.939995
2021-06-03 16:07:40,540 valid_loss 0.531851
2021-06-03 16:08:00,536 valid_acc 44.775997
2021-06-03 16:08:00,537 valid_loss 2.395221
2021-06-03 16:08:20,759 valid_acc 77.811996
2021-06-03 16:08:20,759 valid_loss 0.641364
2021-06-03 16:08:41,132 valid_acc 75.388000
2021-06-03 16:08:41,132 valid_loss 0.724897
2021-06-03 16:09:02,106 valid_acc 82.143997
2021-06-03 16:09:02,106 valid_loss 0.531163
2021-06-03 16:10:44,217 best opid 1
2021-06-03 16:10:44,217 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1550, 0.7001, 0.0651, 0.0487, 0.0311],
        [0.5260, 0.3048, 0.0744, 0.0766, 0.0182]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:10:44,575 train 000 5.998291e-01 79.197685 98.585846
2021-06-03 16:11:00,678 train 050 6.063512e-01 78.967331 98.528542
2021-06-03 16:11:17,286 train 100 6.081578e-01 78.912292 98.524109
2021-06-03 16:11:33,087 train 150 6.088299e-01 78.898209 98.526772
2021-06-03 16:11:48,999 train 200 6.089118e-01 78.897240 98.528351
2021-06-03 16:12:05,391 train 250 6.088017e-01 78.897827 98.533997
2021-06-03 16:12:21,455 train 300 6.084309e-01 78.914635 98.538544
2021-06-03 16:12:37,831 train 350 6.079363e-01 78.933937 98.542007
2021-06-03 16:12:50,810 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1825, 0.6552, 0.0737, 0.0547, 0.0339],
        [0.5526, 0.2721, 0.0770, 0.0804, 0.0179]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:13:08,854 train_acc  81.711998
2021-06-03 16:13:08,854 train_loss 0.528865
2021-06-03 16:13:27,032 valid_acc  78.283997
2021-06-03 16:13:27,032 valid_loss 0.626962
2021-06-03 16:13:27,033 epoch 16
2021-06-03 16:13:27,369 train 000 6.076005e-01 78.948112 98.544731
2021-06-03 16:13:43,068 train 050 6.068140e-01 78.978531 98.547844
2021-06-03 16:13:59,560 train 100 6.060817e-01 79.002571 98.551659
2021-06-03 16:14:15,217 train 150 6.053272e-01 79.033554 98.557602
2021-06-03 16:14:30,894 train 200 6.048186e-01 79.054123 98.561752
2021-06-03 16:14:47,247 train 250 6.038316e-01 79.090477 98.565849
2021-06-03 16:15:03,132 train 300 6.031724e-01 79.114120 98.570358
2021-06-03 16:15:19,479 train 350 6.025677e-01 79.133614 98.575500
2021-06-03 16:15:32,239 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1938, 0.6390, 0.0759, 0.0568, 0.0344],
        [0.5643, 0.2574, 0.0785, 0.0823, 0.0174]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:15:49,911 train_acc  83.895996
2021-06-03 16:15:49,911 train_loss 0.466279
2021-06-03 16:16:07,466 valid_acc  80.383995
2021-06-03 16:16:07,466 valid_loss 0.574391
2021-06-03 16:16:07,471 epoch 17
2021-06-03 16:16:07,824 train 000 6.019471e-01 79.157967 98.578339
2021-06-03 16:16:23,616 train 050 6.008503e-01 79.192505 98.584984
2021-06-03 16:16:39,892 train 100 5.997683e-01 79.231407 98.591072
2021-06-03 16:16:55,579 train 150 5.987169e-01 79.268814 98.595924
2021-06-03 16:17:11,023 train 200 5.979433e-01 79.292198 98.599792
2021-06-03 16:17:26,987 train 250 5.973522e-01 79.309799 98.602463
2021-06-03 16:17:42,449 train 300 5.963725e-01 79.339088 98.608711
2021-06-03 16:17:58,649 train 350 5.954266e-01 79.372871 98.614868
2021-06-03 16:18:11,321 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2043, 0.6236, 0.0791, 0.0585, 0.0345],
        [0.5746, 0.2481, 0.0783, 0.0818, 0.0172]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:18:29,144 train_acc  84.888000
2021-06-03 16:18:29,144 train_loss 0.439247
2021-06-03 16:18:47,171 valid_acc  80.519997
2021-06-03 16:18:47,172 valid_loss 0.572584
2021-06-03 16:18:47,172 epoch 18
2021-06-03 16:18:47,519 train 000 5.948476e-01 79.391602 98.616417
2021-06-03 16:19:03,256 train 050 5.936754e-01 79.436707 98.621552
2021-06-03 16:19:19,573 train 100 5.926380e-01 79.473740 98.627716
2021-06-03 16:19:35,421 train 150 5.917338e-01 79.502632 98.631821
2021-06-03 16:19:51,186 train 200 5.906559e-01 79.543884 98.636322
2021-06-03 16:20:07,353 train 250 5.897690e-01 79.574692 98.639885
2021-06-03 16:20:22,934 train 300 5.886249e-01 79.615097 98.645752
2021-06-03 16:20:39,219 train 350 5.877294e-01 79.642891 98.651115
2021-06-03 16:20:52,117 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2105, 0.6172, 0.0791, 0.0585, 0.0346],
        [0.5822, 0.2429, 0.0767, 0.0811, 0.0171]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:21:10,003 train_acc  86.271996
2021-06-03 16:21:10,003 train_loss 0.395542
2021-06-03 16:21:30,109 valid_acc  82.087997
2021-06-03 16:21:30,109 valid_loss 0.524007
2021-06-03 16:21:30,109 epoch 19
2021-06-03 16:21:30,487 train 000 5.869895e-01 79.669899 98.655968
2021-06-03 16:21:46,480 train 050 5.857271e-01 79.716431 98.660988
2021-06-03 16:22:02,757 train 100 5.845709e-01 79.757362 98.666985
2021-06-03 16:22:18,743 train 150 5.832525e-01 79.803123 98.673103
2021-06-03 16:22:34,590 train 200 5.823959e-01 79.832497 98.677094
2021-06-03 16:22:50,932 train 250 5.813449e-01 79.870644 98.682037
2021-06-03 16:23:06,737 train 300 5.805272e-01 79.898193 98.686935
2021-06-03 16:23:23,119 train 350 5.794736e-01 79.935631 98.691162
2021-06-03 16:23:36,231 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2164, 0.6117, 0.0788, 0.0583, 0.0348],
        [0.5917, 0.2354, 0.0758, 0.0803, 0.0168]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:23:54,695 train_acc  87.035995
2021-06-03 16:23:54,695 train_loss 0.372651
2021-06-03 16:24:12,897 valid_acc  82.472000
2021-06-03 16:24:12,897 valid_loss 0.521962
2021-06-03 16:24:12,897 epoch 20
2021-06-03 16:24:12,897 project
2021-06-03 16:24:33,426 valid_acc 81.664001
2021-06-03 16:24:33,426 valid_loss 0.548807
2021-06-03 16:24:54,059 valid_acc 14.200000
2021-06-03 16:24:54,060 valid_loss 5.799309
2021-06-03 16:25:15,731 valid_acc 73.475998
2021-06-03 16:25:15,731 valid_loss 0.785192
2021-06-03 16:25:40,373 valid_acc 76.311996
2021-06-03 16:25:40,373 valid_loss 0.698170
2021-06-03 16:26:01,907 valid_acc 81.671997
2021-06-03 16:26:01,908 valid_loss 0.539097
2021-06-03 16:26:22,404 valid_acc 81.799995
2021-06-03 16:26:22,404 valid_loss 0.540502
2021-06-03 16:26:42,441 valid_acc 31.459999
2021-06-03 16:26:42,441 valid_loss 2.751896
2021-06-03 16:27:02,150 valid_acc 75.220001
2021-06-03 16:27:02,150 valid_loss 0.718438
2021-06-03 16:27:22,177 valid_acc 69.991997
2021-06-03 16:27:22,177 valid_loss 0.876054
2021-06-03 16:27:42,366 valid_acc 81.239998
2021-06-03 16:27:42,367 valid_loss 0.549734
2021-06-03 16:29:23,261 best opid 1
2021-06-03 16:29:23,261 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5917, 0.2354, 0.0758, 0.0803, 0.0168]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:29:24,137 train 000 5.787947e-01 79.959366 98.692566
2021-06-03 16:29:40,303 train 050 5.840418e-01 79.767677 98.653992
2021-06-03 16:29:56,546 train 100 5.857152e-01 79.714844 98.647675
2021-06-03 16:30:13,196 train 150 5.865052e-01 79.692116 98.648918
2021-06-03 16:30:29,241 train 200 5.870520e-01 79.674721 98.648369
2021-06-03 16:30:46,040 train 250 5.876057e-01 79.656204 98.646873
2021-06-03 16:31:02,162 train 300 5.879771e-01 79.645615 98.647896
2021-06-03 16:31:18,275 train 350 5.884193e-01 79.632858 98.647758
2021-06-03 16:31:31,425 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.6020, 0.2150, 0.0794, 0.0865, 0.0171]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:31:50,185 train_acc  79.515999
2021-06-03 16:31:50,186 train_loss 0.593529
2021-06-03 16:32:09,200 valid_acc  76.888000
2021-06-03 16:32:09,200 valid_loss 0.670868
2021-06-03 16:32:09,200 epoch 21
2021-06-03 16:32:10,093 train 000 5.885345e-01 79.629723 98.649498
2021-06-03 16:32:26,217 train 050 5.886791e-01 79.624207 98.650490
2021-06-03 16:32:42,441 train 100 5.888526e-01 79.621201 98.652596
2021-06-03 16:32:59,160 train 150 5.890762e-01 79.617485 98.654488
2021-06-03 16:33:15,419 train 200 5.889913e-01 79.622543 98.656349
2021-06-03 16:33:32,001 train 250 5.889377e-01 79.624405 98.656166
2021-06-03 16:33:48,078 train 300 5.886477e-01 79.636719 98.658005
2021-06-03 16:34:04,459 train 350 5.885704e-01 79.641586 98.661285
2021-06-03 16:34:17,579 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.6054, 0.2078, 0.0803, 0.0890, 0.0175]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:34:36,265 train_acc  79.584000
2021-06-03 16:34:36,265 train_loss 0.604060
2021-06-03 16:34:54,881 valid_acc  76.227997
2021-06-03 16:34:54,882 valid_loss 0.698125
2021-06-03 16:34:54,882 epoch 22
2021-06-03 16:34:55,777 train 000 5.885294e-01 79.645828 98.662338
2021-06-03 16:35:11,968 train 050 5.882359e-01 79.660347 98.665741
2021-06-03 16:35:28,151 train 100 5.881159e-01 79.663376 98.668922
2021-06-03 16:35:44,788 train 150 5.879570e-01 79.669769 98.671524
2021-06-03 16:36:00,952 train 200 5.877237e-01 79.682655 98.672325
2021-06-03 16:36:17,758 train 250 5.877411e-01 79.684097 98.674179
2021-06-03 16:36:33,949 train 300 5.874622e-01 79.697647 98.675133
2021-06-03 16:36:49,949 train 350 5.872261e-01 79.709290 98.676949
2021-06-03 16:37:03,008 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.6096, 0.2039, 0.0787, 0.0899, 0.0179]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:37:21,350 train_acc  80.727997
2021-06-03 16:37:21,350 train_loss 0.557710
2021-06-03 16:37:39,749 valid_acc  77.155998
2021-06-03 16:37:39,750 valid_loss 0.662648
2021-06-03 16:37:39,750 epoch 23
2021-06-03 16:37:40,659 train 000 5.871292e-01 79.714088 98.678581
2021-06-03 16:37:56,668 train 050 5.871010e-01 79.716873 98.680534
2021-06-03 16:38:12,880 train 100 5.868661e-01 79.728752 98.682640
2021-06-03 16:38:29,477 train 150 5.867015e-01 79.733147 98.683693
2021-06-03 16:38:45,761 train 200 5.864681e-01 79.742935 98.686264
2021-06-03 16:39:02,626 train 250 5.860727e-01 79.755661 98.690331
2021-06-03 16:39:19,493 train 300 5.858077e-01 79.768082 98.691994
2021-06-03 16:39:36,737 train 350 5.855450e-01 79.777863 98.694649
2021-06-03 16:39:50,019 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.6120, 0.1992, 0.0796, 0.0909, 0.0183]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:40:12,157 train_acc  82.755997
2021-06-03 16:40:12,157 train_loss 0.501291
2021-06-03 16:40:32,878 valid_acc  79.568001
2021-06-03 16:40:32,878 valid_loss 0.599770
2021-06-03 16:40:32,878 epoch 24
2021-06-03 16:40:32,878 project
2021-06-03 16:40:53,494 valid_acc 79.624001
2021-06-03 16:40:53,494 valid_loss 0.602627
2021-06-03 16:41:14,611 valid_acc 19.344000
2021-06-03 16:41:14,611 valid_loss 2.887111
2021-06-03 16:41:35,590 valid_acc 61.891998
2021-06-03 16:41:35,590 valid_loss 1.088021
2021-06-03 16:41:55,923 valid_acc 53.051998
2021-06-03 16:41:55,923 valid_loss 1.373328
2021-06-03 16:42:16,239 valid_acc 79.208000
2021-06-03 16:42:16,239 valid_loss 0.612706
2021-06-03 16:44:02,166 best opid 1
2021-06-03 16:44:02,167 tensor([[0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2021-06-03 16:44:02,516 train 000 5.854620e-01 79.781822 98.693802
2021-06-03 16:44:18,531 train 050 5.928677e-01 79.490074 98.597458
2021-06-03 16:44:34,972 train 100 5.989912e-01 79.244934 98.537590
2021-06-03 16:44:50,942 train 150 6.049362e-01 79.006470 98.481949
2021-06-03 16:45:07,416 train 200 6.105909e-01 78.781425 98.430161
2021-06-03 16:45:23,601 train 250 6.161085e-01 78.568298 98.381500
2021-06-03 16:45:40,150 train 300 6.215584e-01 78.359306 98.331886
2021-06-03 16:45:56,015 train 350 6.265607e-01 78.168694 98.291946
2021-06-03 16:46:09,010 tensor([[0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2021-06-03 16:46:28,202 train_acc  42.848000
2021-06-03 16:46:28,203 train_loss 1.576023
2021-06-03 16:46:46,856 valid_acc  42.604000
2021-06-03 16:46:46,856 valid_loss 1.595717
