2021-06-03 11:45:19,360 args = Namespace(arch_learning_rate=0.0003, arch_weight_decay=0.001, batch_size=64, ckpt_interval=20, cutout=False, cutout_length=16, cutout_prob=1.0, data='../data', dataset='cifar10', dev='proj', edge_decision='random', epochs=100, expid_tag='none', fast=False, gpu='auto', grad_clip=5, init_channels=16, layers=8, learning_rate=0.025, learning_rate_min=0.001, log_tag='', method='darts-proj', model_path='saved_models', momentum=0.9, proj_crit='acc', proj_intv=5, report_freq=50, resume_epoch=100, resume_expid='search-darts-201-1', save='../experiments/nasbench201/search-darts-201-1', search_space='nas-bench-201', seed=1, train_portion=0.5, weight_decay=0.0003)
2021-06-03 11:45:19,360 gpu device = 0
2021-06-03 11:45:33,169 param size = 1.686106MB
2021-06-03 11:45:34,147 loading checkpoint from darts-proj-201
2021-06-03 11:45:34,147 => loading checkpoint '../experiments/nasbench201/search-darts-201-1/checkpoint_100.pth.tar'
2021-06-03 11:45:34,562 => loaded checkpoint '../experiments/nasbench201/search-darts-201-1/checkpoint_100.pth.tar' (epoch 99)
2021-06-03 11:45:47,472 tensor([[0.0758, 0.7742, 0.0500, 0.0761, 0.0240],
        [0.0629, 0.8134, 0.0390, 0.0579, 0.0269],
        [0.3339, 0.4742, 0.0610, 0.0774, 0.0534],
        [0.0267, 0.8163, 0.0471, 0.0904, 0.0194],
        [0.0857, 0.7082, 0.0716, 0.0946, 0.0399],
        [0.1554, 0.7029, 0.0538, 0.0598, 0.0280]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 11:46:06,373 train_acc  95.519997
2021-06-03 11:46:06,373 train_loss 0.139611
2021-06-03 11:46:24,078 valid_acc  85.951996
2021-06-03 11:46:24,078 valid_loss 0.440088
2021-06-03 11:46:24,081 epoch 0
2021-06-03 11:46:24,081 project
2021-06-03 11:46:43,855 valid_acc 85.636002
2021-06-03 11:46:43,855 valid_loss 0.456656
2021-06-03 11:47:04,321 valid_acc 17.076000
2021-06-03 11:47:04,321 valid_loss 5.992900
2021-06-03 11:47:23,980 valid_acc 77.851997
2021-06-03 11:47:23,981 valid_loss 0.690861
2021-06-03 11:47:43,870 valid_acc 59.424000
2021-06-03 11:47:43,870 valid_loss 1.348833
2021-06-03 11:48:03,747 valid_acc 85.335999
2021-06-03 11:48:03,747 valid_loss 0.458674
2021-06-03 11:48:23,970 valid_acc 85.391998
2021-06-03 11:48:23,970 valid_loss 0.457716
2021-06-03 11:48:44,328 valid_acc 35.939999
2021-06-03 11:48:44,328 valid_loss 3.216769
2021-06-03 11:49:04,250 valid_acc 84.243996
2021-06-03 11:49:04,251 valid_loss 0.492248
2021-06-03 11:49:24,107 valid_acc 80.951996
2021-06-03 11:49:24,107 valid_loss 0.599109
2021-06-03 11:49:44,426 valid_acc 85.687996
2021-06-03 11:49:44,426 valid_loss 0.456043
2021-06-03 11:50:04,930 valid_acc 85.531998
2021-06-03 11:50:04,930 valid_loss 0.462290
2021-06-03 11:50:24,439 valid_acc 80.127998
2021-06-03 11:50:24,440 valid_loss 0.682709
2021-06-03 11:50:43,900 valid_acc 81.872002
2021-06-03 11:50:43,900 valid_loss 0.564986
2021-06-03 11:51:03,963 valid_acc 77.568001
2021-06-03 11:51:03,964 valid_loss 0.700154
2021-06-03 11:51:23,964 valid_acc 85.391998
2021-06-03 11:51:23,965 valid_loss 0.463229
2021-06-03 11:51:43,696 valid_acc 85.671997
2021-06-03 11:51:43,696 valid_loss 0.453173
2021-06-03 11:52:03,362 valid_acc 10.024000
2021-06-03 11:52:03,362 valid_loss 6.438155
2021-06-03 11:52:23,012 valid_acc 81.375999
2021-06-03 11:52:23,012 valid_loss 0.568865
2021-06-03 11:52:43,095 valid_acc 58.688000
2021-06-03 11:52:43,095 valid_loss 1.325724
2021-06-03 11:53:03,083 valid_acc 85.439995
2021-06-03 11:53:03,083 valid_loss 0.455646
2021-06-03 11:53:22,784 valid_acc 85.435997
2021-06-03 11:53:22,784 valid_loss 0.458612
2021-06-03 11:53:43,179 valid_acc 51.028000
2021-06-03 11:53:43,179 valid_loss 2.215327
2021-06-03 11:54:03,210 valid_acc 78.599998
2021-06-03 11:54:03,210 valid_loss 0.657830
2021-06-03 11:54:22,942 valid_acc 64.279999
2021-06-03 11:54:22,942 valid_loss 1.118633
2021-06-03 11:54:42,894 valid_acc 85.292000
2021-06-03 11:54:42,895 valid_loss 0.458935
2021-06-03 11:55:02,790 valid_acc 85.367996
2021-06-03 11:55:02,790 valid_loss 0.457383
2021-06-03 11:55:24,627 valid_acc 32.784000
2021-06-03 11:55:24,628 valid_loss 3.761394
2021-06-03 11:55:46,914 valid_acc 80.815994
2021-06-03 11:55:46,914 valid_loss 0.588106
2021-06-03 11:56:07,750 valid_acc 72.807999
2021-06-03 11:56:07,751 valid_loss 0.870168
2021-06-03 11:56:27,440 valid_acc 85.475998
2021-06-03 11:56:27,440 valid_loss 0.460254
2021-06-03 11:58:05,814 best opid 1
2021-06-03 11:58:05,814 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0629, 0.8134, 0.0390, 0.0579, 0.0269],
        [0.3339, 0.4742, 0.0610, 0.0774, 0.0534],
        [0.0267, 0.8163, 0.0471, 0.0904, 0.0194],
        [0.0857, 0.7082, 0.0716, 0.0946, 0.0399],
        [0.1554, 0.7029, 0.0538, 0.0598, 0.0280]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 11:58:06,288 train 000 3.171460e+00 14.062500 62.500000
2021-06-03 11:58:23,616 train 050 1.803109e+00 36.764706 86.213242
2021-06-03 11:58:41,921 train 100 1.654613e+00 41.398514 88.845917
2021-06-03 11:58:58,729 train 150 1.527046e+00 46.295528 90.749168
2021-06-03 11:59:14,597 train 200 1.417376e+00 50.163246 92.156403
2021-06-03 11:59:31,063 train 250 1.326221e+00 53.336655 93.189743
2021-06-03 11:59:46,888 train 300 1.250303e+00 56.213661 93.942062
2021-06-03 12:00:03,300 train 350 1.192590e+00 58.293270 94.475601
2021-06-03 12:00:16,287 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0804, 0.7770, 0.0460, 0.0676, 0.0289],
        [0.3974, 0.4113, 0.0635, 0.0796, 0.0481],
        [0.0335, 0.7912, 0.0538, 0.1003, 0.0213],
        [0.1110, 0.6744, 0.0754, 0.0977, 0.0414],
        [0.1998, 0.6403, 0.0624, 0.0696, 0.0280]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:00:35,309 train_acc  71.512001
2021-06-03 12:00:35,309 train_loss 0.857509
2021-06-03 12:00:53,743 valid_acc  69.351997
2021-06-03 12:00:53,743 valid_loss 0.932858
2021-06-03 12:00:53,743 epoch 1
2021-06-03 12:00:54,114 train 000 1.143328e+00 60.026333 94.881111
2021-06-03 12:01:10,256 train 050 1.097638e+00 61.668556 95.287292
2021-06-03 12:01:26,826 train 100 1.056426e+00 63.189678 95.642639
2021-06-03 12:01:42,900 train 150 1.021580e+00 64.470345 95.915070
2021-06-03 12:01:58,816 train 200 9.894735e-01 65.605850 96.157303
2021-06-03 12:02:15,207 train 250 9.614344e-01 66.591171 96.359337
2021-06-03 12:02:31,091 train 300 9.353250e-01 67.449844 96.547989
2021-06-03 12:02:47,645 train 350 9.118237e-01 68.251724 96.719620
2021-06-03 12:03:00,776 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0934, 0.7500, 0.0512, 0.0758, 0.0296],
        [0.4332, 0.3774, 0.0650, 0.0799, 0.0444],
        [0.0390, 0.7690, 0.0594, 0.1103, 0.0224],
        [0.1285, 0.6481, 0.0799, 0.1021, 0.0415],
        [0.2285, 0.6039, 0.0658, 0.0745, 0.0273]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:03:21,362 train_acc  82.360001
2021-06-03 12:03:21,362 train_loss 0.505633
2021-06-03 12:03:41,474 valid_acc  78.823997
2021-06-03 12:03:41,474 valid_loss 0.635167
2021-06-03 12:03:41,474 epoch 2
2021-06-03 12:03:41,818 train 000 8.943469e-01 68.901810 96.834053
2021-06-03 12:03:57,837 train 050 8.723779e-01 69.632393 96.975441
2021-06-03 12:04:14,407 train 100 8.549735e-01 70.202255 97.097267
2021-06-03 12:04:30,467 train 150 8.369457e-01 70.845062 97.211044
2021-06-03 12:04:46,443 train 200 8.216121e-01 71.417664 97.310066
2021-06-03 12:05:02,806 train 250 8.064138e-01 71.954468 97.391922
2021-06-03 12:05:18,627 train 300 7.913378e-01 72.448891 97.476326
2021-06-03 12:05:35,078 train 350 7.795586e-01 72.892746 97.560165
2021-06-03 12:05:48,092 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1031, 0.7311, 0.0543, 0.0818, 0.0296],
        [0.4570, 0.3560, 0.0650, 0.0803, 0.0417],
        [0.0430, 0.7568, 0.0623, 0.1152, 0.0228],
        [0.1413, 0.6305, 0.0822, 0.1056, 0.0405],
        [0.2492, 0.5789, 0.0680, 0.0775, 0.0264]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:06:06,796 train_acc  83.723999
2021-06-03 12:06:06,796 train_loss 0.463618
2021-06-03 12:06:25,852 valid_acc  79.236000
2021-06-03 12:06:25,853 valid_loss 0.630957
2021-06-03 12:06:25,853 epoch 3
2021-06-03 12:06:26,225 train 000 7.705026e-01 73.197540 97.620697
2021-06-03 12:06:42,176 train 050 7.574790e-01 73.662216 97.696259
2021-06-03 12:06:58,393 train 100 7.448327e-01 74.108810 97.765884
2021-06-03 12:07:14,018 train 150 7.348067e-01 74.473213 97.818436
2021-06-03 12:07:29,688 train 200 7.249615e-01 74.822456 97.875130
2021-06-03 12:07:45,873 train 250 7.156660e-01 75.151543 97.931129
2021-06-03 12:08:01,660 train 300 7.077798e-01 75.434944 97.972710
2021-06-03 12:08:18,142 train 350 6.996764e-01 75.715141 98.015678
2021-06-03 12:08:30,884 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1083, 0.7201, 0.0558, 0.0866, 0.0292],
        [0.4714, 0.3452, 0.0635, 0.0799, 0.0399],
        [0.0450, 0.7514, 0.0636, 0.1174, 0.0226],
        [0.1476, 0.6246, 0.0820, 0.1065, 0.0392],
        [0.2618, 0.5677, 0.0675, 0.0774, 0.0256]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:08:48,754 train_acc  85.767998
2021-06-03 12:08:48,754 train_loss 0.401377
2021-06-03 12:09:06,438 valid_acc  80.848000
2021-06-03 12:09:06,438 valid_loss 0.570778
2021-06-03 12:09:06,438 epoch 4
2021-06-03 12:09:06,778 train 000 6.929296e-01 75.961388 98.049248
2021-06-03 12:09:22,464 train 050 6.838122e-01 76.277306 98.098076
2021-06-03 12:09:38,701 train 100 6.762491e-01 76.509430 98.142097
2021-06-03 12:09:54,631 train 150 6.688886e-01 76.775429 98.181725
2021-06-03 12:10:11,942 train 200 6.627386e-01 76.979370 98.212006
2021-06-03 12:10:29,047 train 250 6.570205e-01 77.169495 98.247520
2021-06-03 12:10:44,606 train 300 6.504049e-01 77.387138 98.286995
2021-06-03 12:11:00,729 train 350 6.436738e-01 77.622002 98.323593
2021-06-03 12:11:13,364 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1129, 0.7130, 0.0557, 0.0894, 0.0289],
        [0.4816, 0.3368, 0.0628, 0.0804, 0.0384],
        [0.0468, 0.7470, 0.0645, 0.1194, 0.0223],
        [0.1535, 0.6198, 0.0817, 0.1070, 0.0381],
        [0.2723, 0.5565, 0.0679, 0.0784, 0.0249]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:11:31,213 train_acc  87.851997
2021-06-03 12:11:31,213 train_loss 0.352212
2021-06-03 12:11:49,406 valid_acc  82.367996
2021-06-03 12:11:49,406 valid_loss 0.525385
2021-06-03 12:11:49,406 epoch 5
2021-06-03 12:11:49,406 project
2021-06-03 12:12:09,359 valid_acc 81.579994
2021-06-03 12:12:09,359 valid_loss 0.553533
2021-06-03 12:12:28,589 valid_acc 42.975998
2021-06-03 12:12:28,589 valid_loss 2.588086
2021-06-03 12:12:48,526 valid_acc 79.127998
2021-06-03 12:12:48,527 valid_loss 0.621987
2021-06-03 12:13:08,351 valid_acc 71.012001
2021-06-03 12:13:08,351 valid_loss 0.872378
2021-06-03 12:13:27,892 valid_acc 81.556000
2021-06-03 12:13:27,892 valid_loss 0.550688
2021-06-03 12:13:47,387 valid_acc 81.528000
2021-06-03 12:13:47,387 valid_loss 0.552245
2021-06-03 12:14:07,850 valid_acc 74.851997
2021-06-03 12:14:07,850 valid_loss 0.846019
2021-06-03 12:14:27,410 valid_acc 77.528000
2021-06-03 12:14:27,411 valid_loss 0.668137
2021-06-03 12:14:46,983 valid_acc 73.491997
2021-06-03 12:14:46,983 valid_loss 0.781919
2021-06-03 12:15:06,931 valid_acc 81.292000
2021-06-03 12:15:06,931 valid_loss 0.552059
2021-06-03 12:15:26,566 valid_acc 81.332001
2021-06-03 12:15:26,567 valid_loss 0.554828
2021-06-03 12:15:49,790 valid_acc 10.820000
2021-06-03 12:15:49,791 valid_loss 6.430012
2021-06-03 12:16:12,183 valid_acc 75.811996
2021-06-03 12:16:12,183 valid_loss 0.703810
2021-06-03 12:16:33,141 valid_acc 46.807999
2021-06-03 12:16:33,142 valid_loss 1.675682
2021-06-03 12:16:55,808 valid_acc 81.587997
2021-06-03 12:16:55,809 valid_loss 0.552649
2021-06-03 12:17:15,994 valid_acc 81.491997
2021-06-03 12:17:15,994 valid_loss 0.549950
2021-06-03 12:17:35,756 valid_acc 12.888000
2021-06-03 12:17:35,756 valid_loss 5.760182
2021-06-03 12:17:55,518 valid_acc 73.675995
2021-06-03 12:17:55,518 valid_loss 0.784118
2021-06-03 12:18:15,362 valid_acc 56.511997
2021-06-03 12:18:15,362 valid_loss 1.325296
2021-06-03 12:18:34,891 valid_acc 81.155998
2021-06-03 12:18:34,891 valid_loss 0.562470
2021-06-03 12:18:54,394 valid_acc 81.431999
2021-06-03 12:18:54,395 valid_loss 0.554137
2021-06-03 12:19:14,181 valid_acc 39.775997
2021-06-03 12:19:14,182 valid_loss 2.921564
2021-06-03 12:19:33,767 valid_acc 73.979996
2021-06-03 12:19:33,767 valid_loss 0.770634
2021-06-03 12:19:53,132 valid_acc 61.391998
2021-06-03 12:19:53,132 valid_loss 1.179236
2021-06-03 12:20:12,672 valid_acc 81.239998
2021-06-03 12:20:12,673 valid_loss 0.554601
2021-06-03 12:21:50,576 best opid 1
2021-06-03 12:21:50,576 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4816, 0.3368, 0.0628, 0.0804, 0.0384],
        [0.0468, 0.7470, 0.0645, 0.1194, 0.0223],
        [0.1535, 0.6198, 0.0817, 0.1070, 0.0381],
        [0.2723, 0.5565, 0.0679, 0.0784, 0.0249]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:21:50,930 train 000 6.394570e-01 77.760986 98.345650
2021-06-03 12:22:07,095 train 050 6.442436e-01 77.596207 98.331566
2021-06-03 12:22:22,616 train 100 6.442897e-01 77.590065 98.344795
2021-06-03 12:22:38,710 train 150 6.433718e-01 77.634705 98.353683
2021-06-03 12:22:54,396 train 200 6.418602e-01 77.699760 98.356354
2021-06-03 12:23:10,221 train 250 6.400027e-01 77.772499 98.363861
2021-06-03 12:23:26,431 train 300 6.384671e-01 77.826759 98.382828
2021-06-03 12:23:42,285 train 350 6.368293e-01 77.885452 98.402321
2021-06-03 12:23:55,095 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4900, 0.3143, 0.0690, 0.0911, 0.0358],
        [0.0522, 0.7309, 0.0679, 0.1259, 0.0231],
        [0.1708, 0.5985, 0.0838, 0.1093, 0.0377],
        [0.3068, 0.5198, 0.0693, 0.0801, 0.0240]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:24:12,973 train_acc  82.984001
2021-06-03 12:24:12,973 train_loss 0.487298
2021-06-03 12:24:30,891 valid_acc  78.591995
2021-06-03 12:24:30,891 valid_loss 0.618604
2021-06-03 12:24:30,891 epoch 6
2021-06-03 12:24:31,207 train 000 6.351281e-01 77.950073 98.414009
2021-06-03 12:24:47,441 train 050 6.323273e-01 78.042465 98.434074
2021-06-03 12:25:03,141 train 100 6.300930e-01 78.123405 98.446289
2021-06-03 12:25:19,388 train 150 6.282050e-01 78.196709 98.456757
2021-06-03 12:25:35,127 train 200 6.260975e-01 78.267143 98.473572
2021-06-03 12:25:50,982 train 250 6.236867e-01 78.350517 98.484924
2021-06-03 12:26:07,195 train 300 6.211509e-01 78.452003 98.496429
2021-06-03 12:26:23,071 train 350 6.185573e-01 78.556686 98.510414
2021-06-03 12:26:35,866 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4909, 0.3039, 0.0728, 0.0981, 0.0344],
        [0.0552, 0.7244, 0.0693, 0.1280, 0.0231],
        [0.1803, 0.5878, 0.0846, 0.1106, 0.0367],
        [0.3256, 0.5018, 0.0691, 0.0803, 0.0231]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:26:53,968 train_acc  84.456001
2021-06-03 12:26:53,968 train_loss 0.449979
2021-06-03 12:27:12,124 valid_acc  79.916000
2021-06-03 12:27:12,124 valid_loss 0.591233
2021-06-03 12:27:12,124 epoch 7
2021-06-03 12:27:12,462 train 000 6.163645e-01 78.632385 98.521111
2021-06-03 12:27:28,760 train 050 6.131944e-01 78.742203 98.536438
2021-06-03 12:27:44,743 train 100 6.103064e-01 78.849800 98.550674
2021-06-03 12:28:01,146 train 150 6.076362e-01 78.941208 98.567123
2021-06-03 12:28:17,030 train 200 6.052840e-01 79.008217 98.578224
2021-06-03 12:28:32,880 train 250 6.028121e-01 79.100716 98.590523
2021-06-03 12:28:49,258 train 300 6.006808e-01 79.176788 98.601898
2021-06-03 12:29:05,110 train 350 5.980572e-01 79.262047 98.615952
2021-06-03 12:29:18,040 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4922, 0.2957, 0.0754, 0.1035, 0.0333],
        [0.0578, 0.7156, 0.0711, 0.1325, 0.0230],
        [0.1889, 0.5811, 0.0842, 0.1100, 0.0358],
        [0.3417, 0.4870, 0.0681, 0.0809, 0.0222]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:29:36,168 train_acc  86.596001
2021-06-03 12:29:36,169 train_loss 0.380440
2021-06-03 12:29:54,987 valid_acc  82.051994
2021-06-03 12:29:54,987 valid_loss 0.538747
2021-06-03 12:29:54,988 epoch 8
2021-06-03 12:29:55,369 train 000 5.959008e-01 79.333115 98.628937
2021-06-03 12:30:11,716 train 050 5.932724e-01 79.434135 98.643631
2021-06-03 12:30:29,322 train 100 5.906101e-01 79.521858 98.654007
2021-06-03 12:30:45,976 train 150 5.876927e-01 79.621208 98.670258
2021-06-03 12:31:01,926 train 200 5.852349e-01 79.714745 98.683197
2021-06-03 12:31:17,832 train 250 5.830104e-01 79.796730 98.695763
2021-06-03 12:31:34,281 train 300 5.810370e-01 79.858978 98.707489
2021-06-03 12:31:50,171 train 350 5.787634e-01 79.937431 98.720695
2021-06-03 12:32:03,256 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4927, 0.2909, 0.0765, 0.1074, 0.0325],
        [0.0592, 0.7114, 0.0720, 0.1347, 0.0226],
        [0.1939, 0.5787, 0.0825, 0.1101, 0.0349],
        [0.3519, 0.4785, 0.0670, 0.0810, 0.0215]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:32:21,990 train_acc  87.031998
2021-06-03 12:32:21,990 train_loss 0.372465
2021-06-03 12:32:43,272 valid_acc  82.079994
2021-06-03 12:32:43,272 valid_loss 0.536020
2021-06-03 12:32:43,272 epoch 9
2021-06-03 12:32:43,622 train 000 5.770177e-01 79.999466 98.730576
2021-06-03 12:33:00,160 train 050 5.744517e-01 80.089279 98.744438
2021-06-03 12:33:16,265 train 100 5.718147e-01 80.185257 98.759201
2021-06-03 12:33:32,521 train 150 5.700097e-01 80.247498 98.768448
2021-06-03 12:33:48,158 train 200 5.672767e-01 80.348015 98.779129
2021-06-03 12:34:03,980 train 250 5.654026e-01 80.411011 98.787872
2021-06-03 12:34:20,215 train 300 5.635135e-01 80.470314 98.796799
2021-06-03 12:34:35,889 train 350 5.612906e-01 80.548279 98.805077
2021-06-03 12:34:48,555 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4918, 0.2869, 0.0781, 0.1113, 0.0319],
        [0.0604, 0.7088, 0.0721, 0.1362, 0.0225],
        [0.1984, 0.5774, 0.0817, 0.1083, 0.0343],
        [0.3604, 0.4714, 0.0662, 0.0809, 0.0211]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:35:06,602 train_acc  86.731995
2021-06-03 12:35:06,602 train_loss 0.378874
2021-06-03 12:35:24,652 valid_acc  81.627998
2021-06-03 12:35:24,652 valid_loss 0.554322
2021-06-03 12:35:24,653 epoch 10
2021-06-03 12:35:24,653 project
2021-06-03 12:35:44,389 valid_acc 81.335999
2021-06-03 12:35:44,390 valid_loss 0.559851
2021-06-03 12:36:04,465 valid_acc 79.075996
2021-06-03 12:36:04,465 valid_loss 0.661061
2021-06-03 12:36:24,191 valid_acc 77.500000
2021-06-03 12:36:24,192 valid_loss 0.670229
2021-06-03 12:36:44,324 valid_acc 69.655998
2021-06-03 12:36:44,324 valid_loss 0.916903
2021-06-03 12:37:04,537 valid_acc 81.139999
2021-06-03 12:37:04,537 valid_loss 0.562982
2021-06-03 12:37:24,556 valid_acc 80.995995
2021-06-03 12:37:24,556 valid_loss 0.571093
2021-06-03 12:37:45,047 valid_acc 10.943999
2021-06-03 12:37:45,047 valid_loss 6.397346
2021-06-03 12:38:05,129 valid_acc 71.375999
2021-06-03 12:38:05,129 valid_loss 0.850032
2021-06-03 12:38:25,098 valid_acc 32.375999
2021-06-03 12:38:25,098 valid_loss 2.260559
2021-06-03 12:38:45,133 valid_acc 81.084000
2021-06-03 12:38:45,133 valid_loss 0.565396
2021-06-03 12:39:05,450 valid_acc 81.339996
2021-06-03 12:39:05,451 valid_loss 0.561063
2021-06-03 12:39:25,035 valid_acc 14.804000
2021-06-03 12:39:25,035 valid_loss 5.401689
2021-06-03 12:39:44,715 valid_acc 71.052002
2021-06-03 12:39:44,715 valid_loss 0.868489
2021-06-03 12:40:05,869 valid_acc 54.799999
2021-06-03 12:40:05,870 valid_loss 1.381122
2021-06-03 12:40:28,611 valid_acc 80.903999
2021-06-03 12:40:28,611 valid_loss 0.566076
2021-06-03 12:40:48,342 valid_acc 81.243996
2021-06-03 12:40:48,343 valid_loss 0.562222
2021-06-03 12:41:10,053 valid_acc 27.348000
2021-06-03 12:41:10,053 valid_loss 3.856464
2021-06-03 12:41:34,131 valid_acc 75.543999
2021-06-03 12:41:34,131 valid_loss 0.722388
2021-06-03 12:41:57,594 valid_acc 62.051998
2021-06-03 12:41:57,594 valid_loss 1.194849
2021-06-03 12:42:20,834 valid_acc 80.820000
2021-06-03 12:42:20,834 valid_loss 0.566652
2021-06-03 12:44:05,679 best opid 3
2021-06-03 12:44:05,679 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0604, 0.7088, 0.0721, 0.1362, 0.0225],
        [0.1984, 0.5774, 0.0817, 0.1083, 0.0343],
        [0.3604, 0.4714, 0.0662, 0.0809, 0.0211]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:44:06,063 train 000 5.609998e-01 80.589371 98.797508
2021-06-03 12:44:23,160 train 050 5.860050e-01 79.898048 98.516563
2021-06-03 12:44:39,784 train 100 5.987994e-01 79.417778 98.410309
2021-06-03 12:44:57,476 train 150 6.090374e-01 79.039452 98.342476
2021-06-03 12:45:13,356 train 200 6.164578e-01 78.765060 98.310150
2021-06-03 12:45:29,601 train 250 6.226477e-01 78.547638 98.282745
2021-06-03 12:45:47,048 train 300 6.269593e-01 78.392952 98.264900
2021-06-03 12:46:04,438 train 350 6.298847e-01 78.283737 98.255554
2021-06-03 12:46:17,513 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0600, 0.7053, 0.0736, 0.1384, 0.0226],
        [0.1962, 0.5791, 0.0821, 0.1084, 0.0343],
        [0.3677, 0.4611, 0.0672, 0.0833, 0.0206]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:46:41,035 train_acc  71.463997
2021-06-03 12:46:41,035 train_loss 0.811516
2021-06-03 12:47:02,014 valid_acc  69.759995
2021-06-03 12:47:02,014 valid_loss 0.866199
2021-06-03 12:47:02,014 epoch 11
2021-06-03 12:47:02,386 train 000 6.318829e-01 78.213799 98.250587
2021-06-03 12:47:18,564 train 050 6.341232e-01 78.136948 98.244835
2021-06-03 12:47:34,524 train 100 6.353054e-01 78.092400 98.248085
2021-06-03 12:47:51,971 train 150 6.362838e-01 78.049911 98.249519
2021-06-03 12:48:09,816 train 200 6.371245e-01 78.028168 98.251953
2021-06-03 12:48:26,985 train 250 6.373835e-01 78.015144 98.257774
2021-06-03 12:48:44,616 train 300 6.373883e-01 78.013962 98.262444
2021-06-03 12:49:01,298 train 350 6.373323e-01 78.019859 98.266350
2021-06-03 12:49:13,710 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0615, 0.6935, 0.0768, 0.1449, 0.0234],
        [0.1997, 0.5719, 0.0838, 0.1097, 0.0349],
        [0.3840, 0.4414, 0.0689, 0.0851, 0.0206]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:49:32,755 train_acc  79.355995
2021-06-03 12:49:32,755 train_loss 0.588225
2021-06-03 12:49:51,251 valid_acc  76.547997
2021-06-03 12:49:51,251 valid_loss 0.686423
2021-06-03 12:49:51,251 epoch 12
2021-06-03 12:49:51,628 train 000 6.367654e-01 78.041687 98.273369
2021-06-03 12:50:07,605 train 050 6.358407e-01 78.066635 98.281693
2021-06-03 12:50:23,949 train 100 6.352196e-01 78.089432 98.288216
2021-06-03 12:50:39,875 train 150 6.344122e-01 78.116280 98.297508
2021-06-03 12:50:55,672 train 200 6.339815e-01 78.132675 98.302460
2021-06-03 12:51:11,983 train 250 6.332644e-01 78.156952 98.307617
2021-06-03 12:51:27,758 train 300 6.319045e-01 78.203621 98.317062
2021-06-03 12:51:44,207 train 350 6.306432e-01 78.249664 98.326012
2021-06-03 12:51:56,575 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0620, 0.6868, 0.0782, 0.1491, 0.0239],
        [0.2005, 0.5695, 0.0844, 0.1103, 0.0352],
        [0.3945, 0.4278, 0.0700, 0.0873, 0.0204]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:52:15,255 train_acc  83.991997
2021-06-03 12:52:15,255 train_loss 0.459874
2021-06-03 12:52:33,519 valid_acc  79.867996
2021-06-03 12:52:33,520 valid_loss 0.590855
2021-06-03 12:52:33,520 epoch 13
2021-06-03 12:52:33,859 train 000 6.295728e-01 78.277504 98.335091
2021-06-03 12:52:49,833 train 050 6.280078e-01 78.332687 98.343407
2021-06-03 12:53:06,315 train 100 6.264142e-01 78.382568 98.353371
2021-06-03 12:53:22,092 train 150 6.248915e-01 78.432999 98.363731
2021-06-03 12:53:37,953 train 200 6.235956e-01 78.473297 98.370354
2021-06-03 12:53:54,368 train 250 6.222254e-01 78.523384 98.378311
2021-06-03 12:54:10,268 train 300 6.207998e-01 78.571678 98.388161
2021-06-03 12:54:26,774 train 350 6.192369e-01 78.622818 98.398682
2021-06-03 12:54:39,406 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0616, 0.6830, 0.0790, 0.1525, 0.0239],
        [0.1989, 0.5714, 0.0842, 0.1103, 0.0352],
        [0.4024, 0.4174, 0.0712, 0.0888, 0.0202]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:54:59,059 train_acc  86.208000
2021-06-03 12:54:59,059 train_loss 0.392474
2021-06-03 12:55:17,585 valid_acc  81.883995
2021-06-03 12:55:17,585 valid_loss 0.533069
2021-06-03 12:55:17,585 epoch 14
2021-06-03 12:55:17,926 train 000 6.181047e-01 78.658188 98.406006
2021-06-03 12:55:33,925 train 050 6.163298e-01 78.717613 98.414215
2021-06-03 12:55:50,235 train 100 6.148347e-01 78.761948 98.423683
2021-06-03 12:56:06,206 train 150 6.131633e-01 78.816338 98.432152
2021-06-03 12:56:22,238 train 200 6.112127e-01 78.881348 98.442673
2021-06-03 12:56:38,591 train 250 6.095909e-01 78.937294 98.451096
2021-06-03 12:56:54,365 train 300 6.080862e-01 78.980080 98.458557
2021-06-03 12:57:10,493 train 350 6.066266e-01 79.031258 98.468842
2021-06-03 12:57:23,027 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0605, 0.6851, 0.0780, 0.1526, 0.0238],
        [0.1949, 0.5775, 0.0830, 0.1096, 0.0350],
        [0.4049, 0.4152, 0.0705, 0.0894, 0.0200]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 12:57:41,132 train_acc  87.012001
2021-06-03 12:57:41,132 train_loss 0.373231
2021-06-03 12:57:59,279 valid_acc  81.972000
2021-06-03 12:57:59,279 valid_loss 0.537346
2021-06-03 12:57:59,279 epoch 15
2021-06-03 12:57:59,279 project
2021-06-03 12:58:19,024 valid_acc 81.792000
2021-06-03 12:58:19,024 valid_loss 0.549785
2021-06-03 12:58:38,717 valid_acc 11.184000
2021-06-03 12:58:38,717 valid_loss 6.355189
2021-06-03 12:58:58,144 valid_acc 79.779999
2021-06-03 12:58:58,144 valid_loss 0.597460
2021-06-03 12:59:17,747 valid_acc 69.031998
2021-06-03 12:59:17,747 valid_loss 0.947136
2021-06-03 12:59:37,162 valid_acc 81.795998
2021-06-03 12:59:37,162 valid_loss 0.546197
2021-06-03 12:59:56,673 valid_acc 81.603996
2021-06-03 12:59:56,673 valid_loss 0.542244
2021-06-03 13:00:16,543 valid_acc 12.440000
2021-06-03 13:00:16,544 valid_loss 5.845174
2021-06-03 13:00:36,421 valid_acc 80.047997
2021-06-03 13:00:36,421 valid_loss 0.588957
2021-06-03 13:00:55,691 valid_acc 77.612000
2021-06-03 13:00:55,692 valid_loss 0.659869
2021-06-03 13:01:15,281 valid_acc 81.708000
2021-06-03 13:01:15,281 valid_loss 0.552785
2021-06-03 13:01:34,841 valid_acc 82.087997
2021-06-03 13:01:34,841 valid_loss 0.535857
2021-06-03 13:01:54,633 valid_acc 30.420000
2021-06-03 13:01:54,633 valid_loss 3.804959
2021-06-03 13:02:15,788 valid_acc 80.159996
2021-06-03 13:02:15,788 valid_loss 0.583904
2021-06-03 13:02:35,540 valid_acc 75.844002
2021-06-03 13:02:35,540 valid_loss 0.713323
2021-06-03 13:02:55,423 valid_acc 82.000000
2021-06-03 13:02:55,424 valid_loss 0.536628
2021-06-03 13:04:34,553 best opid 1
2021-06-03 13:04:34,554 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1949, 0.5775, 0.0830, 0.1096, 0.0350],
        [0.4049, 0.4152, 0.0705, 0.0894, 0.0200]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 13:04:34,871 train 000 6.056005e-01 79.068108 98.471733
2021-06-03 13:04:50,663 train 050 6.101304e-01 78.903885 98.444206
2021-06-03 13:05:06,974 train 100 6.106436e-01 78.891846 98.445984
2021-06-03 13:05:22,648 train 150 6.107748e-01 78.891449 98.449295
2021-06-03 13:05:38,334 train 200 6.106346e-01 78.888733 98.453064
2021-06-03 13:05:54,442 train 250 6.100492e-01 78.907547 98.457542
2021-06-03 13:06:10,042 train 300 6.094829e-01 78.924019 98.463463
2021-06-03 13:06:26,240 train 350 6.087219e-01 78.954323 98.469292
2021-06-03 13:06:38,998 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2187, 0.5324, 0.0921, 0.1206, 0.0361],
        [0.4350, 0.3751, 0.0741, 0.0959, 0.0198]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 13:06:56,706 train_acc  82.655998
2021-06-03 13:06:56,706 train_loss 0.501819
2021-06-03 13:07:14,249 valid_acc  79.068001
2021-06-03 13:07:14,250 valid_loss 0.618184
2021-06-03 13:07:14,254 epoch 16
2021-06-03 13:07:14,593 train 000 6.080046e-01 78.980858 98.473488
2021-06-03 13:07:30,153 train 050 6.069571e-01 79.023415 98.480148
2021-06-03 13:07:46,448 train 100 6.063998e-01 79.040459 98.484985
2021-06-03 13:08:02,278 train 150 6.053105e-01 79.080421 98.491692
2021-06-03 13:08:17,902 train 200 6.043400e-01 79.114189 98.496361
2021-06-03 13:08:34,190 train 250 6.033062e-01 79.145515 98.502396
2021-06-03 13:08:49,865 train 300 6.020960e-01 79.187340 98.509056
2021-06-03 13:09:06,138 train 350 6.010448e-01 79.223793 98.516563
2021-06-03 13:09:18,820 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2256, 0.5188, 0.0950, 0.1242, 0.0364],
        [0.4496, 0.3589, 0.0747, 0.0971, 0.0196]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 13:09:36,722 train_acc  84.479996
2021-06-03 13:09:36,723 train_loss 0.446908
2021-06-03 13:09:56,221 valid_acc  80.248001
2021-06-03 13:09:56,221 valid_loss 0.568698
2021-06-03 13:09:56,221 epoch 17
2021-06-03 13:09:56,603 train 000 6.002358e-01 79.247597 98.520462
2021-06-03 13:10:14,195 train 050 5.987522e-01 79.301086 98.528244
2021-06-03 13:10:31,353 train 100 5.977151e-01 79.337326 98.534523
2021-06-03 13:10:47,454 train 150 5.967824e-01 79.369812 98.539101
2021-06-03 13:11:03,795 train 200 5.956234e-01 79.405022 98.546585
2021-06-03 13:11:22,298 train 250 5.942907e-01 79.450821 98.552132
2021-06-03 13:11:39,099 train 300 5.931011e-01 79.491928 98.559418
2021-06-03 13:11:57,676 train 350 5.922853e-01 79.514336 98.564362
2021-06-03 13:12:11,836 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2330, 0.5054, 0.0984, 0.1272, 0.0361],
        [0.4608, 0.3473, 0.0746, 0.0979, 0.0194]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 13:12:33,550 train_acc  86.491997
2021-06-03 13:12:33,551 train_loss 0.389625
2021-06-03 13:12:54,932 valid_acc  81.951996
2021-06-03 13:12:54,932 valid_loss 0.539221
2021-06-03 13:12:54,933 epoch 18
2021-06-03 13:12:55,317 train 000 5.911778e-01 79.553131 98.569984
2021-06-03 13:13:11,470 train 050 5.897865e-01 79.598419 98.577431
2021-06-03 13:13:28,066 train 100 5.883816e-01 79.645935 98.583900
2021-06-03 13:13:44,265 train 150 5.871966e-01 79.688423 98.589401
2021-06-03 13:14:00,771 train 200 5.861424e-01 79.723419 98.596138
2021-06-03 13:14:18,418 train 250 5.849842e-01 79.763512 98.602768
2021-06-03 13:14:34,211 train 300 5.839525e-01 79.795593 98.609093
2021-06-03 13:14:50,542 train 350 5.827072e-01 79.835709 98.615555
2021-06-03 13:15:03,556 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2362, 0.5012, 0.0986, 0.1278, 0.0361],
        [0.4681, 0.3409, 0.0740, 0.0976, 0.0194]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 13:15:23,383 train_acc  87.171997
2021-06-03 13:15:23,383 train_loss 0.378793
2021-06-03 13:15:44,018 valid_acc  82.535995
2021-06-03 13:15:44,018 valid_loss 0.526073
2021-06-03 13:15:44,018 epoch 19
2021-06-03 13:15:44,339 train 000 5.816841e-01 79.868187 98.620186
2021-06-03 13:16:00,307 train 050 5.804458e-01 79.904404 98.626068
2021-06-03 13:16:16,873 train 100 5.790144e-01 79.953850 98.632919
2021-06-03 13:16:33,140 train 150 5.777761e-01 80.000374 98.638649
2021-06-03 13:16:49,429 train 200 5.765393e-01 80.040955 98.643890
2021-06-03 13:17:06,106 train 250 5.752773e-01 80.088943 98.649254
2021-06-03 13:17:22,073 train 300 5.740705e-01 80.130051 98.655373
2021-06-03 13:17:38,716 train 350 5.728924e-01 80.167404 98.661812
2021-06-03 13:17:51,655 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2387, 0.4980, 0.0986, 0.1282, 0.0364],
        [0.4764, 0.3352, 0.0726, 0.0962, 0.0195]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 13:18:10,494 train_acc  87.311996
2021-06-03 13:18:10,495 train_loss 0.363007
2021-06-03 13:18:28,799 valid_acc  82.171997
2021-06-03 13:18:28,799 valid_loss 0.536879
2021-06-03 13:18:28,799 epoch 20
2021-06-03 13:18:28,799 project
2021-06-03 13:18:49,359 valid_acc 82.187996
2021-06-03 13:18:49,360 valid_loss 0.527535
2021-06-03 13:19:09,977 valid_acc 18.639999
2021-06-03 13:19:09,977 valid_loss 4.723499
2021-06-03 13:19:30,673 valid_acc 77.563995
2021-06-03 13:19:30,673 valid_loss 0.657623
2021-06-03 13:19:51,355 valid_acc 70.103996
2021-06-03 13:19:51,355 valid_loss 0.877353
2021-06-03 13:20:11,933 valid_acc 82.043999
2021-06-03 13:20:11,933 valid_loss 0.535921
2021-06-03 13:20:32,369 valid_acc 82.584000
2021-06-03 13:20:32,369 valid_loss 0.522303
2021-06-03 13:20:53,019 valid_acc 22.232000
2021-06-03 13:20:53,019 valid_loss 3.641368
2021-06-03 13:21:13,886 valid_acc 78.664001
2021-06-03 13:21:13,886 valid_loss 0.621590
2021-06-03 13:21:35,243 valid_acc 72.400002
2021-06-03 13:21:35,243 valid_loss 0.807720
2021-06-03 13:21:56,549 valid_acc 82.391998
2021-06-03 13:21:56,549 valid_loss 0.526268
2021-06-03 13:23:39,683 best opid 1
2021-06-03 13:23:39,684 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4764, 0.3352, 0.0726, 0.0962, 0.0195]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 13:23:40,556 train 000 5.723034e-01 80.186737 98.663368
2021-06-03 13:23:56,544 train 050 5.801694e-01 79.893265 98.581268
2021-06-03 13:24:12,502 train 100 5.863008e-01 79.665085 98.535133
2021-06-03 13:24:29,056 train 150 5.912401e-01 79.483742 98.501366
2021-06-03 13:24:45,013 train 200 5.953522e-01 79.345589 98.476784
2021-06-03 13:25:01,648 train 250 5.989876e-01 79.211494 98.459496
2021-06-03 13:25:17,704 train 300 6.021196e-01 79.100227 98.445107
2021-06-03 13:25:33,791 train 350 6.047698e-01 79.002762 98.434341
2021-06-03 13:25:46,759 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5024, 0.3013, 0.0738, 0.1027, 0.0198]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 13:26:05,121 train_acc  66.047997
2021-06-03 13:26:05,121 train_loss 1.002817
2021-06-03 13:26:23,846 valid_acc  65.075996
2021-06-03 13:26:23,846 valid_loss 1.035166
2021-06-03 13:26:23,846 epoch 21
2021-06-03 13:26:24,719 train 000 6.065746e-01 78.940475 98.427429
2021-06-03 13:26:40,747 train 050 6.082467e-01 78.881203 98.422951
2021-06-03 13:26:56,793 train 100 6.095498e-01 78.840523 98.418900
2021-06-03 13:27:13,309 train 150 6.104630e-01 78.814735 98.418823
2021-06-03 13:27:29,403 train 200 6.113132e-01 78.785156 98.418556
2021-06-03 13:27:45,956 train 250 6.117492e-01 78.774971 98.417564
2021-06-03 13:28:01,930 train 300 6.120489e-01 78.765823 98.418968
2021-06-03 13:28:17,910 train 350 6.127210e-01 78.738693 98.418159
2021-06-03 13:28:30,934 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5184, 0.2774, 0.0742, 0.1097, 0.0202]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 13:28:49,163 train_acc  74.023994
2021-06-03 13:28:49,164 train_loss 0.762892
2021-06-03 13:29:07,613 valid_acc  71.944000
2021-06-03 13:29:07,613 valid_loss 0.824979
2021-06-03 13:29:07,614 epoch 22
2021-06-03 13:29:08,474 train 000 6.128492e-01 78.737206 98.418915
2021-06-03 13:29:24,213 train 050 6.130280e-01 78.729141 98.420464
2021-06-03 13:29:39,987 train 100 6.131721e-01 78.725128 98.422897
2021-06-03 13:29:56,532 train 150 6.132061e-01 78.724022 98.425659
2021-06-03 13:30:12,275 train 200 6.133682e-01 78.719368 98.426620
2021-06-03 13:30:28,499 train 250 6.133234e-01 78.721489 98.428093
2021-06-03 13:30:44,310 train 300 6.134741e-01 78.717606 98.428673
2021-06-03 13:31:00,098 train 350 6.134358e-01 78.723206 98.431694
2021-06-03 13:31:12,897 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5279, 0.2646, 0.0739, 0.1130, 0.0206]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 13:31:31,147 train_acc  78.339996
2021-06-03 13:31:31,148 train_loss 0.638546
2021-06-03 13:31:49,487 valid_acc  75.344002
2021-06-03 13:31:49,488 valid_loss 0.716143
2021-06-03 13:31:49,488 epoch 23
2021-06-03 13:31:50,381 train 000 6.136066e-01 78.718719 98.432007
2021-06-03 13:32:06,138 train 050 6.133332e-01 78.730301 98.434280
2021-06-03 13:32:21,921 train 100 6.132814e-01 78.732475 98.436363
2021-06-03 13:32:38,193 train 150 6.132222e-01 78.737022 98.438591
2021-06-03 13:32:54,063 train 200 6.129391e-01 78.753418 98.441307
2021-06-03 13:33:10,520 train 250 6.129912e-01 78.747818 98.442642
2021-06-03 13:33:26,497 train 300 6.128849e-01 78.756752 98.444801
2021-06-03 13:33:42,173 train 350 6.127938e-01 78.756042 98.447273
2021-06-03 13:33:55,073 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5326, 0.2564, 0.0741, 0.1160, 0.0210]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 13:34:12,937 train_acc  81.939995
2021-06-03 13:34:12,937 train_loss 0.530075
2021-06-03 13:34:30,719 valid_acc  78.851997
2021-06-03 13:34:30,720 valid_loss 0.613134
2021-06-03 13:34:30,720 epoch 24
2021-06-03 13:34:30,720 project
2021-06-03 13:34:50,508 valid_acc 78.787994
2021-06-03 13:34:50,509 valid_loss 0.613907
2021-06-03 13:35:11,598 valid_acc 15.752000
2021-06-03 13:35:11,599 valid_loss 3.394366
2021-06-03 13:35:31,477 valid_acc 72.348000
2021-06-03 13:35:31,477 valid_loss 0.808764
2021-06-03 13:35:51,597 valid_acc 36.528000
2021-06-03 13:35:51,597 valid_loss 1.857306
2021-06-03 13:36:11,515 valid_acc 78.612000
2021-06-03 13:36:11,515 valid_loss 0.626324
2021-06-03 13:37:50,139 best opid 1
2021-06-03 13:37:50,139 tensor([[0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2021-06-03 13:37:50,489 train 000 6.129474e-01 78.753433 98.444160
2021-06-03 13:38:06,157 train 050 6.201859e-01 78.473274 98.347984
2021-06-03 13:38:22,300 train 100 6.262488e-01 78.238609 98.283493
2021-06-03 13:38:38,052 train 150 6.318085e-01 78.018715 98.235748
2021-06-03 13:38:54,502 train 200 6.373611e-01 77.795074 98.185081
2021-06-03 13:39:10,263 train 250 6.425754e-01 77.597130 98.139801
2021-06-03 13:39:26,381 train 300 6.472570e-01 77.417221 98.105812
2021-06-03 13:39:42,202 train 350 6.520835e-01 77.226952 98.063660
2021-06-03 13:39:54,997 tensor([[0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2021-06-03 13:40:13,255 train_acc  38.287998
2021-06-03 13:40:13,255 train_loss 1.699432
2021-06-03 13:40:31,210 valid_acc  38.335999
2021-06-03 13:40:31,210 valid_loss 1.705138
