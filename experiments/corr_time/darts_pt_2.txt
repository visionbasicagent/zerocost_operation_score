2021-06-03 16:53:12,669 args = Namespace(arch_learning_rate=0.0003, arch_weight_decay=0.001, batch_size=64, ckpt_interval=20, cutout=False, cutout_length=16, cutout_prob=1.0, data='../data', dataset='cifar10', dev='proj', edge_decision='random', epochs=100, expid_tag='none', fast=False, gpu='auto', grad_clip=5, init_channels=16, layers=8, learning_rate=0.025, learning_rate_min=0.001, log_tag='', method='darts-proj', model_path='saved_models', momentum=0.9, proj_crit='acc', proj_intv=5, report_freq=50, resume_epoch=100, resume_expid='search-darts-201-2', save='../experiments/nasbench201/search-darts-201-2', search_space='nas-bench-201', seed=2, train_portion=0.5, weight_decay=0.0003)
2021-06-03 16:53:12,670 gpu device = 0
2021-06-03 16:53:26,541 param size = 1.686106MB
2021-06-03 16:53:27,515 loading checkpoint from darts-proj-201
2021-06-03 16:53:27,515 => loading checkpoint '../experiments/nasbench201/search-darts-201-2/checkpoint_100.pth.tar'
2021-06-03 16:53:27,933 => loaded checkpoint '../experiments/nasbench201/search-darts-201-2/checkpoint_100.pth.tar' (epoch 99)
2021-06-03 16:53:40,886 tensor([[0.0646, 0.7922, 0.0389, 0.0788, 0.0254],
        [0.0594, 0.7825, 0.0602, 0.0627, 0.0353],
        [0.3853, 0.4440, 0.0509, 0.0580, 0.0619],
        [0.0253, 0.7768, 0.0732, 0.1057, 0.0189],
        [0.0619, 0.7629, 0.0597, 0.0816, 0.0339],
        [0.1585, 0.6551, 0.0728, 0.0815, 0.0321]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 16:54:00,408 train_acc  95.963997
2021-06-03 16:54:00,408 train_loss 0.128789
2021-06-03 16:54:19,435 valid_acc  86.327995
2021-06-03 16:54:19,435 valid_loss 0.425256
2021-06-03 16:54:19,438 epoch 0
2021-06-03 16:54:19,439 project
2021-06-03 16:54:41,427 valid_acc 85.736000
2021-06-03 16:54:41,427 valid_loss 0.454368
2021-06-03 16:55:03,626 valid_acc 11.776000
2021-06-03 16:55:03,626 valid_loss 6.640668
2021-06-03 16:55:26,627 valid_acc 82.951996
2021-06-03 16:55:26,627 valid_loss 0.533344
2021-06-03 16:55:48,962 valid_acc 59.739998
2021-06-03 16:55:48,962 valid_loss 1.378209
2021-06-03 16:56:10,356 valid_acc 85.295998
2021-06-03 16:56:10,356 valid_loss 0.461200
2021-06-03 16:56:31,269 valid_acc 85.715996
2021-06-03 16:56:31,269 valid_loss 0.458151
2021-06-03 16:56:52,871 valid_acc 37.236000
2021-06-03 16:56:52,871 valid_loss 3.095621
2021-06-03 16:57:14,100 valid_acc 81.615997
2021-06-03 16:57:14,100 valid_loss 0.577181
2021-06-03 16:57:37,481 valid_acc 79.491997
2021-06-03 16:57:37,481 valid_loss 0.650647
2021-06-03 16:58:00,236 valid_acc 85.535995
2021-06-03 16:58:00,236 valid_loss 0.455883
2021-06-03 16:58:22,231 valid_acc 85.659996
2021-06-03 16:58:22,231 valid_loss 0.455325
2021-06-03 16:58:43,887 valid_acc 80.835999
2021-06-03 16:58:43,887 valid_loss 0.673633
2021-06-03 16:59:05,631 valid_acc 83.175995
2021-06-03 16:59:05,631 valid_loss 0.527301
2021-06-03 16:59:26,910 valid_acc 81.167999
2021-06-03 16:59:26,911 valid_loss 0.596408
2021-06-03 16:59:47,988 valid_acc 85.599998
2021-06-03 16:59:47,988 valid_loss 0.452351
2021-06-03 17:00:09,225 valid_acc 85.519997
2021-06-03 17:00:09,225 valid_loss 0.456252
2021-06-03 17:00:31,099 valid_acc 11.696000
2021-06-03 17:00:31,099 valid_loss 6.036301
2021-06-03 17:00:52,932 valid_acc 79.075996
2021-06-03 17:00:52,932 valid_loss 0.657717
2021-06-03 17:01:13,946 valid_acc 53.520000
2021-06-03 17:01:13,946 valid_loss 1.554618
2021-06-03 17:01:34,877 valid_acc 85.463997
2021-06-03 17:01:34,877 valid_loss 0.456161
2021-06-03 17:01:56,222 valid_acc 85.736000
2021-06-03 17:01:56,222 valid_loss 0.455587
2021-06-03 17:02:16,982 valid_acc 46.099998
2021-06-03 17:02:16,982 valid_loss 2.528517
2021-06-03 17:02:37,777 valid_acc 82.051994
2021-06-03 17:02:37,777 valid_loss 0.558361
2021-06-03 17:02:59,481 valid_acc 70.552002
2021-06-03 17:02:59,481 valid_loss 0.922248
2021-06-03 17:03:20,589 valid_acc 85.631996
2021-06-03 17:03:20,589 valid_loss 0.455637
2021-06-03 17:03:41,804 valid_acc 85.403999
2021-06-03 17:03:41,804 valid_loss 0.464518
2021-06-03 17:04:02,960 valid_acc 36.467999
2021-06-03 17:04:02,960 valid_loss 3.319688
2021-06-03 17:04:23,951 valid_acc 78.731995
2021-06-03 17:04:23,951 valid_loss 0.677489
2021-06-03 17:04:45,078 valid_acc 69.439995
2021-06-03 17:04:45,078 valid_loss 0.983467
2021-06-03 17:05:06,081 valid_acc 85.287994
2021-06-03 17:05:06,081 valid_loss 0.458917
2021-06-03 17:06:50,895 best opid 1
2021-06-03 17:06:50,895 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0594, 0.7825, 0.0602, 0.0627, 0.0353],
        [0.3853, 0.4440, 0.0509, 0.0580, 0.0619],
        [0.0253, 0.7768, 0.0732, 0.1057, 0.0189],
        [0.0619, 0.7629, 0.0597, 0.0816, 0.0339],
        [0.1585, 0.6551, 0.0728, 0.0815, 0.0321]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:06:51,386 train 000 2.265065e+00 34.375000 78.125000
2021-06-03 17:07:07,558 train 050 1.421640e+00 51.930149 92.095589
2021-06-03 17:07:24,164 train 100 1.183798e+00 59.545174 94.399750
2021-06-03 17:07:40,072 train 150 1.082945e+00 62.737995 95.478065
2021-06-03 17:07:56,036 train 200 1.010423e+00 65.088615 96.167595
2021-06-03 17:08:12,755 train 250 9.555663e-01 66.950951 96.607323
2021-06-03 17:08:28,882 train 300 9.112822e-01 68.474876 96.947670
2021-06-03 17:08:45,531 train 350 8.771735e-01 69.640312 97.199966
2021-06-03 17:08:58,703 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0743, 0.7468, 0.0693, 0.0729, 0.0367],
        [0.4538, 0.3813, 0.0519, 0.0583, 0.0547],
        [0.0307, 0.7549, 0.0808, 0.1133, 0.0203],
        [0.0804, 0.7314, 0.0652, 0.0874, 0.0356],
        [0.1982, 0.5972, 0.0822, 0.0912, 0.0312]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:09:17,838 train_acc  78.487999
2021-06-03 17:09:17,839 train_loss 0.618399
2021-06-03 17:09:36,742 valid_acc  75.211998
2021-06-03 17:09:36,742 valid_loss 0.726349
2021-06-03 17:09:36,742 epoch 1
2021-06-03 17:09:37,148 train 000 8.555401e-01 70.383820 97.354774
2021-06-03 17:09:53,222 train 050 8.285623e-01 71.352249 97.519814
2021-06-03 17:10:10,041 train 100 8.057402e-01 72.136406 97.679886
2021-06-03 17:10:26,265 train 150 7.840344e-01 72.960419 97.824837
2021-06-03 17:10:42,253 train 200 7.653751e-01 73.621384 97.937355
2021-06-03 17:10:58,894 train 250 7.476667e-01 74.254822 98.044510
2021-06-03 17:11:14,948 train 300 7.357698e-01 74.663383 98.118111
2021-06-03 17:11:31,586 train 350 7.214227e-01 75.158012 98.198631
2021-06-03 17:11:44,615 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0824, 0.7290, 0.0736, 0.0782, 0.0368],
        [0.4828, 0.3561, 0.0519, 0.0581, 0.0510],
        [0.0340, 0.7415, 0.0853, 0.1185, 0.0207],
        [0.0903, 0.7151, 0.0678, 0.0914, 0.0353],
        [0.2181, 0.5713, 0.0859, 0.0947, 0.0301]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:12:03,553 train_acc  81.888000
2021-06-03 17:12:03,554 train_loss 0.523623
2021-06-03 17:12:22,045 valid_acc  77.708000
2021-06-03 17:12:22,045 valid_loss 0.650118
2021-06-03 17:12:22,045 epoch 2
2021-06-03 17:12:22,431 train 000 7.112498e-01 75.489380 98.242256
2021-06-03 17:12:38,601 train 050 6.994559e-01 75.936844 98.287773
2021-06-03 17:12:55,385 train 100 6.876628e-01 76.314110 98.344078
2021-06-03 17:13:11,434 train 150 6.763151e-01 76.731361 98.392662
2021-06-03 17:13:27,388 train 200 6.675237e-01 77.032959 98.437897
2021-06-03 17:13:43,851 train 250 6.581448e-01 77.364372 98.490852
2021-06-03 17:14:00,191 train 300 6.480464e-01 77.715698 98.543251
2021-06-03 17:14:17,853 train 350 6.411579e-01 77.928352 98.573082
2021-06-03 17:14:31,236 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0885, 0.7187, 0.0751, 0.0809, 0.0369],
        [0.5016, 0.3401, 0.0518, 0.0581, 0.0484],
        [0.0366, 0.7290, 0.0889, 0.1246, 0.0209],
        [0.0975, 0.7070, 0.0687, 0.0918, 0.0349],
        [0.2329, 0.5519, 0.0884, 0.0977, 0.0290]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:14:49,628 train_acc  84.375999
2021-06-03 17:14:49,629 train_loss 0.454479
2021-06-03 17:15:11,011 valid_acc  79.823997
2021-06-03 17:15:11,011 valid_loss 0.609890
2021-06-03 17:15:11,011 epoch 3
2021-06-03 17:15:11,367 train 000 6.338382e-01 78.206596 98.603859
2021-06-03 17:15:27,192 train 050 6.259040e-01 78.469025 98.639221
2021-06-03 17:15:45,073 train 100 6.190979e-01 78.686287 98.663216
2021-06-03 17:16:02,593 train 150 6.118645e-01 78.917839 98.697205
2021-06-03 17:16:20,367 train 200 6.062199e-01 79.085861 98.726440
2021-06-03 17:16:38,334 train 250 6.004003e-01 79.287094 98.756920
2021-06-03 17:16:54,406 train 300 5.948846e-01 79.477844 98.781082
2021-06-03 17:17:11,290 train 350 5.888807e-01 79.685837 98.808792
2021-06-03 17:17:25,772 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0937, 0.7086, 0.0773, 0.0839, 0.0365],
        [0.5154, 0.3278, 0.0520, 0.0586, 0.0461],
        [0.0386, 0.7239, 0.0898, 0.1268, 0.0209],
        [0.1032, 0.7012, 0.0685, 0.0930, 0.0341],
        [0.2448, 0.5397, 0.0890, 0.0983, 0.0282]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:17:46,996 train_acc  86.559998
2021-06-03 17:17:46,996 train_loss 0.384503
2021-06-03 17:18:06,154 valid_acc  81.068001
2021-06-03 17:18:06,154 valid_loss 0.564986
2021-06-03 17:18:06,155 epoch 4
2021-06-03 17:18:06,515 train 000 5.852594e-01 79.844902 98.821754
2021-06-03 17:18:22,456 train 050 5.795498e-01 80.031761 98.849548
2021-06-03 17:18:38,976 train 100 5.742338e-01 80.231819 98.871918
2021-06-03 17:18:54,897 train 150 5.691331e-01 80.411079 98.897545
2021-06-03 17:19:10,853 train 200 5.648403e-01 80.554474 98.909302
2021-06-03 17:19:27,337 train 250 5.609034e-01 80.680489 98.930763
2021-06-03 17:19:43,427 train 300 5.567178e-01 80.818184 98.941841
2021-06-03 17:19:59,966 train 350 5.532187e-01 80.937256 98.957245
2021-06-03 17:20:13,098 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0979, 0.7032, 0.0776, 0.0853, 0.0360],
        [0.5282, 0.3184, 0.0511, 0.0582, 0.0442],
        [0.0402, 0.7184, 0.0915, 0.1292, 0.0208],
        [0.1075, 0.6979, 0.0684, 0.0928, 0.0334],
        [0.2570, 0.5281, 0.0888, 0.0987, 0.0274]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:20:31,812 train_acc  85.823997
2021-06-03 17:20:31,813 train_loss 0.404416
2021-06-03 17:20:50,734 valid_acc  81.035995
2021-06-03 17:20:50,734 valid_loss 0.569611
2021-06-03 17:20:50,734 epoch 5
2021-06-03 17:20:50,734 project
2021-06-03 17:21:11,846 valid_acc 81.003998
2021-06-03 17:21:11,846 valid_loss 0.564565
2021-06-03 17:21:33,211 valid_acc 45.348000
2021-06-03 17:21:33,211 valid_loss 2.408566
2021-06-03 17:21:54,059 valid_acc 75.692001
2021-06-03 17:21:54,060 valid_loss 0.717204
2021-06-03 17:22:14,910 valid_acc 72.748001
2021-06-03 17:22:14,910 valid_loss 0.806748
2021-06-03 17:22:35,752 valid_acc 80.907997
2021-06-03 17:22:35,752 valid_loss 0.564216
2021-06-03 17:22:56,670 valid_acc 80.916000
2021-06-03 17:22:56,670 valid_loss 0.566834
2021-06-03 17:23:17,699 valid_acc 77.339996
2021-06-03 17:23:17,699 valid_loss 0.746144
2021-06-03 17:23:38,665 valid_acc 78.984001
2021-06-03 17:23:38,666 valid_loss 0.622524
2021-06-03 17:23:59,497 valid_acc 77.551994
2021-06-03 17:23:59,497 valid_loss 0.663840
2021-06-03 17:24:20,054 valid_acc 81.056000
2021-06-03 17:24:20,054 valid_loss 0.561937
2021-06-03 17:24:40,706 valid_acc 80.951996
2021-06-03 17:24:40,706 valid_loss 0.562958
2021-06-03 17:25:01,809 valid_acc 12.752000
2021-06-03 17:25:01,809 valid_loss 5.797724
2021-06-03 17:25:22,456 valid_acc 73.636002
2021-06-03 17:25:22,456 valid_loss 0.778638
2021-06-03 17:25:43,339 valid_acc 44.759998
2021-06-03 17:25:43,340 valid_loss 1.784970
2021-06-03 17:26:04,292 valid_acc 80.939995
2021-06-03 17:26:04,293 valid_loss 0.571258
2021-06-03 17:26:25,814 valid_acc 80.956001
2021-06-03 17:26:25,814 valid_loss 0.566864
2021-06-03 17:26:46,385 valid_acc 13.096000
2021-06-03 17:26:46,385 valid_loss 5.664920
2021-06-03 17:27:07,148 valid_acc 76.851997
2021-06-03 17:27:07,148 valid_loss 0.679905
2021-06-03 17:27:27,770 valid_acc 62.799999
2021-06-03 17:27:27,770 valid_loss 1.094458
2021-06-03 17:27:48,752 valid_acc 81.255997
2021-06-03 17:27:48,752 valid_loss 0.564502
2021-06-03 17:28:10,031 valid_acc 80.832001
2021-06-03 17:28:10,032 valid_loss 0.571372
2021-06-03 17:28:30,926 valid_acc 52.063999
2021-06-03 17:28:30,926 valid_loss 2.121690
2021-06-03 17:28:51,753 valid_acc 68.223999
2021-06-03 17:28:51,753 valid_loss 0.947592
2021-06-03 17:29:12,365 valid_acc 56.483997
2021-06-03 17:29:12,366 valid_loss 1.350051
2021-06-03 17:29:33,220 valid_acc 81.360001
2021-06-03 17:29:33,221 valid_loss 0.558957
2021-06-03 17:31:19,732 best opid 1
2021-06-03 17:31:19,733 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5282, 0.3184, 0.0511, 0.0582, 0.0442],
        [0.0402, 0.7184, 0.0915, 0.1292, 0.0208],
        [0.1075, 0.6979, 0.0684, 0.0928, 0.0334],
        [0.2570, 0.5281, 0.0888, 0.0987, 0.0274]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:31:20,058 train 000 5.507275e-01 81.008926 98.963730
2021-06-03 17:31:36,596 train 050 5.629994e-01 80.578339 98.891342
2021-06-03 17:31:52,487 train 100 5.678133e-01 80.402245 98.879547
2021-06-03 17:32:08,962 train 150 5.703747e-01 80.319168 98.877205
2021-06-03 17:32:24,857 train 200 5.726955e-01 80.248650 98.868454
2021-06-03 17:32:40,790 train 250 5.739893e-01 80.205437 98.867889
2021-06-03 17:32:57,450 train 300 5.743433e-01 80.200882 98.869431
2021-06-03 17:33:13,652 train 350 5.744346e-01 80.197205 98.872269
2021-06-03 17:33:26,903 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5386, 0.2933, 0.0586, 0.0686, 0.0409],
        [0.0461, 0.6944, 0.0994, 0.1384, 0.0217],
        [0.1249, 0.6706, 0.0724, 0.0984, 0.0337],
        [0.2968, 0.4869, 0.0910, 0.0990, 0.0263]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:33:46,572 train_acc  81.636002
2021-06-03 17:33:46,572 train_loss 0.527479
2021-06-03 17:34:05,945 valid_acc  78.043999
2021-06-03 17:34:05,945 valid_loss 0.646355
2021-06-03 17:34:05,945 epoch 6
2021-06-03 17:34:06,289 train 000 5.742152e-01 80.213776 98.877151
2021-06-03 17:34:22,750 train 050 5.742273e-01 80.209969 98.886238
2021-06-03 17:34:38,851 train 100 5.739208e-01 80.215897 98.890480
2021-06-03 17:34:55,482 train 150 5.732037e-01 80.241005 98.889542
2021-06-03 17:35:11,568 train 200 5.721859e-01 80.262672 98.895401
2021-06-03 17:35:27,674 train 250 5.713500e-01 80.287117 98.897415
2021-06-03 17:35:44,605 train 300 5.703110e-01 80.326591 98.901711
2021-06-03 17:36:00,825 train 350 5.693929e-01 80.356483 98.912819
2021-06-03 17:36:13,817 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5407, 0.2832, 0.0626, 0.0741, 0.0393],
        [0.0491, 0.6831, 0.1021, 0.1439, 0.0219],
        [0.1338, 0.6605, 0.0733, 0.0991, 0.0333],
        [0.3175, 0.4683, 0.0914, 0.0974, 0.0255]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:36:32,580 train_acc  83.472000
2021-06-03 17:36:32,581 train_loss 0.478970
2021-06-03 17:36:51,225 valid_acc  79.299995
2021-06-03 17:36:51,225 valid_loss 0.621074
2021-06-03 17:36:51,225 epoch 7
2021-06-03 17:36:51,570 train 000 5.680612e-01 80.399162 98.911827
2021-06-03 17:37:08,210 train 050 5.662394e-01 80.446976 98.920700
2021-06-03 17:37:24,115 train 100 5.650515e-01 80.477669 98.927612
2021-06-03 17:37:40,655 train 150 5.639293e-01 80.508385 98.933739
2021-06-03 17:37:56,570 train 200 5.619460e-01 80.581696 98.943382
2021-06-03 17:38:12,708 train 250 5.599918e-01 80.655693 98.948517
2021-06-03 17:38:29,240 train 300 5.580408e-01 80.721077 98.956055
2021-06-03 17:38:45,137 train 350 5.573825e-01 80.746368 98.959808
2021-06-03 17:38:58,842 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5403, 0.2768, 0.0657, 0.0790, 0.0382],
        [0.0513, 0.6789, 0.1030, 0.1449, 0.0218],
        [0.1405, 0.6542, 0.0734, 0.0994, 0.0325],
        [0.3318, 0.4555, 0.0907, 0.0975, 0.0245]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:39:22,060 train_acc  84.972000
2021-06-03 17:39:22,060 train_loss 0.425885
2021-06-03 17:39:42,817 valid_acc  80.875999
2021-06-03 17:39:42,817 valid_loss 0.566010
2021-06-03 17:39:42,817 epoch 8
2021-06-03 17:39:43,206 train 000 5.564634e-01 80.772652 98.967331
2021-06-03 17:40:01,899 train 050 5.539280e-01 80.857407 98.976700
2021-06-03 17:40:20,164 train 100 5.526237e-01 80.902245 98.979965
2021-06-03 17:40:38,333 train 150 5.508299e-01 80.960014 98.989815
2021-06-03 17:40:55,947 train 200 5.499082e-01 80.990211 98.994667
2021-06-03 17:41:14,353 train 250 5.479474e-01 81.050987 99.002151
2021-06-03 17:41:33,190 train 300 5.463547e-01 81.108620 99.007133
2021-06-03 17:41:49,778 train 350 5.449248e-01 81.156952 99.014671
2021-06-03 17:42:02,845 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5407, 0.2713, 0.0679, 0.0827, 0.0375],
        [0.0533, 0.6744, 0.1039, 0.1463, 0.0221],
        [0.1464, 0.6482, 0.0732, 0.1000, 0.0323],
        [0.3432, 0.4437, 0.0910, 0.0983, 0.0240]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:42:24,057 train_acc  85.863998
2021-06-03 17:42:24,058 train_loss 0.406258
2021-06-03 17:42:42,449 valid_acc  81.591995
2021-06-03 17:42:42,449 valid_loss 0.546964
2021-06-03 17:42:42,449 epoch 9
2021-06-03 17:42:42,808 train 000 5.434570e-01 81.212006 99.020271
2021-06-03 17:42:59,196 train 050 5.415464e-01 81.277817 99.028755
2021-06-03 17:43:15,847 train 100 5.393795e-01 81.348289 99.037865
2021-06-03 17:43:34,395 train 150 5.376362e-01 81.404045 99.044167
2021-06-03 17:43:52,234 train 200 5.363100e-01 81.438553 99.049034
2021-06-03 17:44:10,115 train 250 5.344788e-01 81.501175 99.056267
2021-06-03 17:44:28,296 train 300 5.330812e-01 81.549469 99.058395
2021-06-03 17:44:45,317 train 350 5.317855e-01 81.592476 99.062088
2021-06-03 17:44:58,571 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5401, 0.2662, 0.0704, 0.0866, 0.0368],
        [0.0550, 0.6703, 0.1055, 0.1471, 0.0221],
        [0.1516, 0.6438, 0.0728, 0.1000, 0.0318],
        [0.3546, 0.4328, 0.0909, 0.0983, 0.0233]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:45:17,811 train_acc  87.963997
2021-06-03 17:45:17,811 train_loss 0.343867
2021-06-03 17:45:36,386 valid_acc  82.723999
2021-06-03 17:45:36,386 valid_loss 0.514783
2021-06-03 17:45:36,386 epoch 10
2021-06-03 17:45:36,386 project
2021-06-03 17:45:57,147 valid_acc 82.012001
2021-06-03 17:45:57,147 valid_loss 0.543302
2021-06-03 17:46:18,348 valid_acc 79.619995
2021-06-03 17:46:18,349 valid_loss 0.647659
2021-06-03 17:46:39,262 valid_acc 79.023994
2021-06-03 17:46:39,262 valid_loss 0.628114
2021-06-03 17:46:59,974 valid_acc 71.108002
2021-06-03 17:46:59,974 valid_loss 0.878299
2021-06-03 17:47:20,859 valid_acc 82.087997
2021-06-03 17:47:20,860 valid_loss 0.538588
2021-06-03 17:47:41,315 valid_acc 82.239998
2021-06-03 17:47:41,316 valid_loss 0.532459
2021-06-03 17:48:01,732 valid_acc 12.328000
2021-06-03 17:48:01,732 valid_loss 5.789969
2021-06-03 17:48:22,355 valid_acc 71.771996
2021-06-03 17:48:22,355 valid_loss 0.838555
2021-06-03 17:48:42,969 valid_acc 35.444000
2021-06-03 17:48:42,970 valid_loss 2.129210
2021-06-03 17:49:03,519 valid_acc 82.115997
2021-06-03 17:49:03,519 valid_loss 0.540419
2021-06-03 17:49:24,265 valid_acc 81.963997
2021-06-03 17:49:24,265 valid_loss 0.539620
2021-06-03 17:49:44,979 valid_acc 13.492000
2021-06-03 17:49:44,979 valid_loss 5.521606
2021-06-03 17:50:05,986 valid_acc 76.236000
2021-06-03 17:50:05,986 valid_loss 0.711485
2021-06-03 17:50:26,522 valid_acc 56.688000
2021-06-03 17:50:26,522 valid_loss 1.330455
2021-06-03 17:50:47,393 valid_acc 81.667999
2021-06-03 17:50:47,393 valid_loss 0.542393
2021-06-03 17:51:07,964 valid_acc 82.127998
2021-06-03 17:51:07,964 valid_loss 0.534698
2021-06-03 17:51:28,810 valid_acc 31.743999
2021-06-03 17:51:28,810 valid_loss 3.523917
2021-06-03 17:51:49,449 valid_acc 71.568001
2021-06-03 17:51:49,449 valid_loss 0.847846
2021-06-03 17:52:10,358 valid_acc 59.236000
2021-06-03 17:52:10,358 valid_loss 1.250087
2021-06-03 17:52:31,261 valid_acc 81.835999
2021-06-03 17:52:31,262 valid_loss 0.547431
2021-06-03 17:54:16,755 best opid 3
2021-06-03 17:54:16,755 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0550, 0.6703, 0.1055, 0.1471, 0.0221],
        [0.1516, 0.6438, 0.0728, 0.1000, 0.0318],
        [0.3546, 0.4328, 0.0909, 0.0983, 0.0233]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:54:17,103 train 000 5.313516e-01 81.624702 99.054245
2021-06-03 17:54:33,304 train 050 5.575840e-01 80.959785 98.795326
2021-06-03 17:54:49,448 train 100 5.693639e-01 80.513840 98.705086
2021-06-03 17:55:06,207 train 150 5.776926e-01 80.210968 98.651718
2021-06-03 17:55:22,267 train 200 5.829678e-01 80.029976 98.627045
2021-06-03 17:55:38,976 train 250 5.872273e-01 79.877396 98.608231
2021-06-03 17:55:55,129 train 300 5.904744e-01 79.762238 98.601746
2021-06-03 17:56:11,958 train 350 5.926483e-01 79.681351 98.598717
2021-06-03 17:56:24,609 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0540, 0.6700, 0.1056, 0.1487, 0.0217],
        [0.1482, 0.6475, 0.0734, 0.0998, 0.0312],
        [0.3675, 0.4126, 0.0954, 0.1022, 0.0223]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:56:43,489 train_acc  76.451996
2021-06-03 17:56:43,489 train_loss 0.683803
2021-06-03 17:57:02,491 valid_acc  74.540001
2021-06-03 17:57:02,492 valid_loss 0.748348
2021-06-03 17:57:02,492 epoch 11
2021-06-03 17:57:02,835 train 000 5.935856e-01 79.644737 98.597054
2021-06-03 17:57:18,916 train 050 5.943884e-01 79.611809 98.596298
2021-06-03 17:57:34,975 train 100 5.952597e-01 79.583176 98.596977
2021-06-03 17:57:51,592 train 150 5.954744e-01 79.569595 98.601860
2021-06-03 17:58:08,288 train 200 5.954590e-01 79.565353 98.606987
2021-06-03 17:58:24,922 train 250 5.951740e-01 79.565666 98.614052
2021-06-03 17:58:41,110 train 300 5.949224e-01 79.573441 98.613831
2021-06-03 17:58:57,785 train 350 5.944265e-01 79.586441 98.620003
2021-06-03 17:59:10,444 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0546, 0.6607, 0.1082, 0.1544, 0.0221],
        [0.1495, 0.6445, 0.0738, 0.1007, 0.0315],
        [0.3817, 0.3918, 0.0986, 0.1060, 0.0219]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 17:59:29,421 train_acc  82.947998
2021-06-03 17:59:29,421 train_loss 0.482402
2021-06-03 17:59:48,515 valid_acc  79.619995
2021-06-03 17:59:48,515 valid_loss 0.596971
2021-06-03 17:59:48,515 epoch 12
2021-06-03 17:59:48,861 train 000 5.938589e-01 79.601685 98.625961
2021-06-03 18:00:05,108 train 050 5.929741e-01 79.625999 98.632210
2021-06-03 18:00:21,885 train 100 5.921367e-01 79.660255 98.638664
2021-06-03 18:00:38,062 train 150 5.912128e-01 79.691216 98.647247
2021-06-03 18:00:54,164 train 200 5.903489e-01 79.719627 98.651489
2021-06-03 18:01:10,725 train 250 5.894598e-01 79.750931 98.658180
2021-06-03 18:01:26,834 train 300 5.879001e-01 79.797279 98.665367
2021-06-03 18:01:43,419 train 350 5.864107e-01 79.842400 98.673027
2021-06-03 18:01:55,787 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0548, 0.6539, 0.1105, 0.1586, 0.0223],
        [0.1498, 0.6423, 0.0747, 0.1015, 0.0316],
        [0.3916, 0.3789, 0.1001, 0.1079, 0.0215]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:02:14,350 train_acc  84.792000
2021-06-03 18:02:14,350 train_loss 0.426406
2021-06-03 18:02:32,636 valid_acc  80.759995
2021-06-03 18:02:32,637 valid_loss 0.568769
2021-06-03 18:02:32,637 epoch 13
2021-06-03 18:02:32,969 train 000 5.853332e-01 79.872269 98.678413
2021-06-03 18:02:48,730 train 050 5.837293e-01 79.928963 98.685814
2021-06-03 18:03:04,974 train 100 5.819942e-01 79.987274 98.695183
2021-06-03 18:03:20,632 train 150 5.804538e-01 80.028328 98.702881
2021-06-03 18:03:36,667 train 200 5.793510e-01 80.063576 98.707474
2021-06-03 18:03:54,733 train 250 5.778317e-01 80.110771 98.715492
2021-06-03 18:04:10,809 train 300 5.764430e-01 80.159416 98.722206
2021-06-03 18:04:26,986 train 350 5.749083e-01 80.208023 98.729362
2021-06-03 18:04:39,277 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0537, 0.6545, 0.1102, 0.1593, 0.0223],
        [0.1464, 0.6485, 0.0733, 0.1003, 0.0315],
        [0.3955, 0.3736, 0.1007, 0.1090, 0.0213]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:04:57,522 train_acc  86.099998
2021-06-03 18:04:57,523 train_loss 0.395991
2021-06-03 18:05:15,715 valid_acc  81.652000
2021-06-03 18:05:15,716 valid_loss 0.547531
2021-06-03 18:05:15,716 epoch 14
2021-06-03 18:05:16,057 train 000 5.736657e-01 80.250473 98.734520
2021-06-03 18:05:31,724 train 050 5.720298e-01 80.302261 98.741730
2021-06-03 18:05:47,899 train 100 5.704714e-01 80.350044 98.749100
2021-06-03 18:06:03,644 train 150 5.688450e-01 80.402824 98.756897
2021-06-03 18:06:19,355 train 200 5.672577e-01 80.451904 98.763176
2021-06-03 18:06:35,747 train 250 5.658393e-01 80.494125 98.768799
2021-06-03 18:06:51,456 train 300 5.641654e-01 80.546982 98.776756
2021-06-03 18:07:07,675 train 350 5.625966e-01 80.594902 98.783768
2021-06-03 18:07:20,501 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0524, 0.6580, 0.1092, 0.1580, 0.0224],
        [0.1421, 0.6554, 0.0717, 0.0994, 0.0314],
        [0.3971, 0.3700, 0.1015, 0.1103, 0.0211]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:07:38,575 train_acc  87.699997
2021-06-03 18:07:38,575 train_loss 0.345829
2021-06-03 18:07:56,619 valid_acc  82.680000
2021-06-03 18:07:56,619 valid_loss 0.511823
2021-06-03 18:07:56,619 epoch 15
2021-06-03 18:07:56,619 project
2021-06-03 18:08:16,317 valid_acc 83.223999
2021-06-03 18:08:16,317 valid_loss 0.502809
2021-06-03 18:08:36,352 valid_acc 11.219999
2021-06-03 18:08:36,352 valid_loss 6.530819
2021-06-03 18:08:56,494 valid_acc 78.967995
2021-06-03 18:08:56,494 valid_loss 0.600735
2021-06-03 18:09:16,514 valid_acc 69.463997
2021-06-03 18:09:16,514 valid_loss 0.916014
2021-06-03 18:09:36,607 valid_acc 82.587997
2021-06-03 18:09:36,607 valid_loss 0.511484
2021-06-03 18:09:56,449 valid_acc 82.995995
2021-06-03 18:09:56,449 valid_loss 0.505466
2021-06-03 18:10:16,565 valid_acc 11.224000
2021-06-03 18:10:16,565 valid_loss 6.521153
2021-06-03 18:10:36,595 valid_acc 81.512001
2021-06-03 18:10:36,595 valid_loss 0.545482
2021-06-03 18:10:56,925 valid_acc 78.335999
2021-06-03 18:10:56,926 valid_loss 0.636340
2021-06-03 18:11:16,907 valid_acc 82.208000
2021-06-03 18:11:16,907 valid_loss 0.521663
2021-06-03 18:11:36,991 valid_acc 82.967995
2021-06-03 18:11:36,991 valid_loss 0.504328
2021-06-03 18:11:56,896 valid_acc 42.711998
2021-06-03 18:11:56,896 valid_loss 2.745788
2021-06-03 18:12:16,984 valid_acc 78.835999
2021-06-03 18:12:16,984 valid_loss 0.618715
2021-06-03 18:12:36,902 valid_acc 75.043999
2021-06-03 18:12:36,902 valid_loss 0.737523
2021-06-03 18:12:57,058 valid_acc 83.251999
2021-06-03 18:12:57,058 valid_loss 0.502466
2021-06-03 18:14:36,981 best opid 1
2021-06-03 18:14:36,981 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1421, 0.6554, 0.0717, 0.0994, 0.0314],
        [0.3971, 0.3700, 0.1015, 0.1103, 0.0211]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:14:37,355 train 000 5.619509e-01 80.618774 98.784744
2021-06-03 18:14:53,219 train 050 5.682366e-01 80.398605 98.735802
2021-06-03 18:15:09,750 train 100 5.695944e-01 80.355156 98.731201
2021-06-03 18:15:25,847 train 150 5.701247e-01 80.341286 98.730324
2021-06-03 18:15:41,789 train 200 5.704227e-01 80.327896 98.730995
2021-06-03 18:15:58,257 train 250 5.703042e-01 80.331100 98.733971
2021-06-03 18:16:14,110 train 300 5.702133e-01 80.335510 98.735619
2021-06-03 18:16:30,418 train 350 5.700879e-01 80.345390 98.739510
2021-06-03 18:16:43,269 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1627, 0.6117, 0.0808, 0.1108, 0.0340],
        [0.4262, 0.3335, 0.1042, 0.1150, 0.0211]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:17:01,373 train_acc  82.736000
2021-06-03 18:17:01,374 train_loss 0.492414
2021-06-03 18:17:19,408 valid_acc  79.439995
2021-06-03 18:17:19,409 valid_loss 0.604104
2021-06-03 18:17:19,409 epoch 16
2021-06-03 18:17:19,767 train 000 5.700014e-01 80.342644 98.742950
2021-06-03 18:17:35,638 train 050 5.694342e-01 80.359016 98.744743
2021-06-03 18:17:51,844 train 100 5.689725e-01 80.375877 98.749214
2021-06-03 18:18:07,704 train 150 5.684900e-01 80.393448 98.753616
2021-06-03 18:18:23,488 train 200 5.681185e-01 80.407593 98.755035
2021-06-03 18:18:39,817 train 250 5.676861e-01 80.421043 98.757881
2021-06-03 18:18:55,683 train 300 5.670152e-01 80.444778 98.763786
2021-06-03 18:19:11,935 train 350 5.662884e-01 80.470291 98.769127
2021-06-03 18:19:24,701 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1719, 0.5936, 0.0843, 0.1154, 0.0348],
        [0.4424, 0.3179, 0.1042, 0.1145, 0.0209]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:19:43,193 train_acc  85.575996
2021-06-03 18:19:43,193 train_loss 0.416454
2021-06-03 18:20:01,094 valid_acc  81.264000
2021-06-03 18:20:01,094 valid_loss 0.549278
2021-06-03 18:20:01,094 epoch 17
2021-06-03 18:20:01,460 train 000 5.657273e-01 80.488823 98.772423
2021-06-03 18:20:17,310 train 050 5.649580e-01 80.515518 98.776688
2021-06-03 18:20:33,721 train 100 5.640943e-01 80.543213 98.781815
2021-06-03 18:20:49,653 train 150 5.631140e-01 80.578560 98.785957
2021-06-03 18:21:05,513 train 200 5.624628e-01 80.597855 98.791634
2021-06-03 18:21:21,984 train 250 5.618313e-01 80.619591 98.796539
2021-06-03 18:21:38,024 train 300 5.610543e-01 80.643265 98.801392
2021-06-03 18:21:54,419 train 350 5.601996e-01 80.675095 98.805267
2021-06-03 18:22:07,250 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1786, 0.5816, 0.0860, 0.1186, 0.0351],
        [0.4534, 0.3079, 0.1041, 0.1138, 0.0208]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:22:25,317 train_acc  85.907997
2021-06-03 18:22:25,317 train_loss 0.412786
2021-06-03 18:22:43,698 valid_acc  81.351997
2021-06-03 18:22:43,698 valid_loss 0.541271
2021-06-03 18:22:43,698 epoch 18
2021-06-03 18:22:44,053 train 000 5.595049e-01 80.696304 98.809502
2021-06-03 18:23:00,058 train 050 5.585311e-01 80.723373 98.815262
2021-06-03 18:23:16,493 train 100 5.575028e-01 80.761246 98.819405
2021-06-03 18:23:32,398 train 150 5.563985e-01 80.797493 98.825005
2021-06-03 18:23:48,124 train 200 5.554664e-01 80.833679 98.829468
2021-06-03 18:24:04,390 train 250 5.545742e-01 80.868935 98.833206
2021-06-03 18:24:20,108 train 300 5.535778e-01 80.898811 98.836899
2021-06-03 18:24:36,452 train 350 5.526275e-01 80.931664 98.840118
2021-06-03 18:24:49,250 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1832, 0.5728, 0.0874, 0.1215, 0.0351],
        [0.4633, 0.2993, 0.1036, 0.1132, 0.0206]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:25:07,643 train_acc  85.827995
2021-06-03 18:25:07,644 train_loss 0.406989
2021-06-03 18:25:25,989 valid_acc  81.124001
2021-06-03 18:25:25,989 valid_loss 0.561168
2021-06-03 18:25:25,990 epoch 19
2021-06-03 18:25:26,330 train 000 5.519249e-01 80.953094 98.844788
2021-06-03 18:25:42,283 train 050 5.510715e-01 80.977661 98.849167
2021-06-03 18:25:58,833 train 100 5.501005e-01 81.012077 98.854538
2021-06-03 18:26:14,934 train 150 5.490836e-01 81.045425 98.859215
2021-06-03 18:26:31,051 train 200 5.480807e-01 81.076492 98.864235
2021-06-03 18:26:47,598 train 250 5.471758e-01 81.107140 98.869186
2021-06-03 18:27:03,318 train 300 5.462911e-01 81.137009 98.874893
2021-06-03 18:27:19,592 train 350 5.453202e-01 81.166473 98.880920
2021-06-03 18:27:32,383 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1867, 0.5679, 0.0873, 0.1231, 0.0350],
        [0.4746, 0.2909, 0.1018, 0.1124, 0.0202]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:27:50,387 train_acc  86.863998
2021-06-03 18:27:50,387 train_loss 0.371780
2021-06-03 18:28:09,112 valid_acc  82.003998
2021-06-03 18:28:09,112 valid_loss 0.529436
2021-06-03 18:28:09,112 epoch 20
2021-06-03 18:28:09,112 project
2021-06-03 18:28:28,930 valid_acc 82.084000
2021-06-03 18:28:28,930 valid_loss 0.526069
2021-06-03 18:28:49,694 valid_acc 15.335999
2021-06-03 18:28:49,694 valid_loss 5.569469
2021-06-03 18:29:09,946 valid_acc 77.860001
2021-06-03 18:29:09,946 valid_loss 0.642927
2021-06-03 18:29:30,804 valid_acc 64.467995
2021-06-03 18:29:30,805 valid_loss 1.036354
2021-06-03 18:29:51,991 valid_acc 82.007996
2021-06-03 18:29:51,991 valid_loss 0.528829
2021-06-03 18:30:12,381 valid_acc 82.251999
2021-06-03 18:30:12,381 valid_loss 0.522917
2021-06-03 18:30:31,974 valid_acc 19.528000
2021-06-03 18:30:31,975 valid_loss 3.879955
2021-06-03 18:30:52,081 valid_acc 76.568001
2021-06-03 18:30:52,082 valid_loss 0.684598
2021-06-03 18:31:12,166 valid_acc 64.951996
2021-06-03 18:31:12,166 valid_loss 1.039411
2021-06-03 18:31:32,388 valid_acc 82.320000
2021-06-03 18:31:32,388 valid_loss 0.524391
2021-06-03 18:33:12,741 best opid 1
2021-06-03 18:33:12,741 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4746, 0.2909, 0.1018, 0.1124, 0.0202]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:33:13,618 train 000 5.448405e-01 81.180809 98.881943
2021-06-03 18:33:29,406 train 050 5.523946e-01 80.900482 98.810570
2021-06-03 18:33:45,260 train 100 5.575774e-01 80.711555 98.779373
2021-06-03 18:34:01,756 train 150 5.611115e-01 80.590355 98.760559
2021-06-03 18:34:17,766 train 200 5.632451e-01 80.519783 98.754051
2021-06-03 18:34:34,625 train 250 5.645943e-01 80.475677 98.749382
2021-06-03 18:34:52,091 train 300 5.654949e-01 80.448868 98.748810
2021-06-03 18:35:09,254 train 350 5.664454e-01 80.419510 98.745178
2021-06-03 18:35:22,160 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4906, 0.2666, 0.1037, 0.1185, 0.0206]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:35:40,793 train_acc  76.220001
2021-06-03 18:35:40,794 train_loss 0.686333
2021-06-03 18:36:01,692 valid_acc  74.040001
2021-06-03 18:36:01,692 valid_loss 0.756548
2021-06-03 18:36:01,692 epoch 21
2021-06-03 18:36:02,593 train 000 5.670779e-01 80.400108 98.743584
2021-06-03 18:36:18,957 train 050 5.676332e-01 80.381210 98.743431
2021-06-03 18:36:36,375 train 100 5.681039e-01 80.370636 98.742531
2021-06-03 18:36:54,283 train 150 5.685728e-01 80.354576 98.742393
2021-06-03 18:37:10,809 train 200 5.687457e-01 80.352470 98.742615
2021-06-03 18:37:29,825 train 250 5.691464e-01 80.339478 98.742851
2021-06-03 18:37:47,305 train 300 5.693679e-01 80.337120 98.742706
2021-06-03 18:38:04,793 train 350 5.696407e-01 80.324738 98.743301
2021-06-03 18:38:19,981 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5012, 0.2545, 0.1025, 0.1209, 0.0209]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:38:41,470 train_acc  75.816002
2021-06-03 18:38:41,471 train_loss 0.688523
2021-06-03 18:39:01,113 valid_acc  73.596001
2021-06-03 18:39:01,113 valid_loss 0.771627
2021-06-03 18:39:01,113 epoch 22
2021-06-03 18:39:01,977 train 000 5.698920e-01 80.314476 98.743607
2021-06-03 18:39:17,938 train 050 5.698587e-01 80.319160 98.745811
2021-06-03 18:39:33,957 train 100 5.699084e-01 80.322899 98.746193
2021-06-03 18:39:50,499 train 150 5.699625e-01 80.315155 98.747284
2021-06-03 18:40:06,593 train 200 5.699948e-01 80.312828 98.749252
2021-06-03 18:40:22,970 train 250 5.699531e-01 80.313530 98.752083
2021-06-03 18:40:39,054 train 300 5.698602e-01 80.315285 98.754356
2021-06-03 18:40:54,884 train 350 5.698985e-01 80.313171 98.756607
2021-06-03 18:41:07,905 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5094, 0.2454, 0.1027, 0.1217, 0.0208]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:41:25,979 train_acc  79.867996
2021-06-03 18:41:25,980 train_loss 0.591097
2021-06-03 18:41:44,073 valid_acc  76.891998
2021-06-03 18:41:44,074 valid_loss 0.680237
2021-06-03 18:41:44,074 epoch 23
2021-06-03 18:41:44,946 train 000 5.700215e-01 80.305153 98.757706
2021-06-03 18:42:00,826 train 050 5.699306e-01 80.306396 98.759216
2021-06-03 18:42:16,931 train 100 5.698872e-01 80.306953 98.760368
2021-06-03 18:42:33,654 train 150 5.698319e-01 80.308006 98.762024
2021-06-03 18:42:49,867 train 200 5.696684e-01 80.315857 98.763832
2021-06-03 18:43:06,374 train 250 5.695539e-01 80.318375 98.766129
2021-06-03 18:43:22,408 train 300 5.694438e-01 80.324402 98.766205
2021-06-03 18:43:38,534 train 350 5.694490e-01 80.325676 98.766457
2021-06-03 18:43:51,659 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.5170, 0.2359, 0.1037, 0.1226, 0.0208]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 18:44:11,176 train_acc  78.512001
2021-06-03 18:44:11,177 train_loss 0.623007
2021-06-03 18:44:32,436 valid_acc  75.807999
2021-06-03 18:44:32,436 valid_loss 0.713079
2021-06-03 18:44:32,436 epoch 24
2021-06-03 18:44:32,436 project
2021-06-03 18:44:54,293 valid_acc 78.231995
2021-06-03 18:44:54,293 valid_loss 0.639433
2021-06-03 18:45:15,822 valid_acc 13.920000
2021-06-03 18:45:15,822 valid_loss 3.246048
2021-06-03 18:45:39,954 valid_acc 64.419998
2021-06-03 18:45:39,954 valid_loss 1.019097
2021-06-03 18:46:01,870 valid_acc 34.247997
2021-06-03 18:46:01,870 valid_loss 1.973438
2021-06-03 18:46:23,761 valid_acc 77.615997
2021-06-03 18:46:23,761 valid_loss 0.653788
2021-06-03 18:48:07,484 best opid 1
2021-06-03 18:48:07,484 tensor([[0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2021-06-03 18:48:07,871 train 000 5.695033e-01 80.322762 98.764465
2021-06-03 18:48:23,749 train 050 5.769951e-01 80.037094 98.661781
2021-06-03 18:48:40,123 train 100 5.834702e-01 79.786766 98.593155
2021-06-03 18:48:55,833 train 150 5.895624e-01 79.544144 98.531158
2021-06-03 18:49:12,046 train 200 5.951149e-01 79.327881 98.484818
2021-06-03 18:49:27,883 train 250 6.007315e-01 79.107689 98.437820
2021-06-03 18:49:44,186 train 300 6.060689e-01 78.899948 98.392441
2021-06-03 18:50:00,005 train 350 6.109893e-01 78.713951 98.353477
2021-06-03 18:50:12,700 tensor([[0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2021-06-03 18:50:30,868 train_acc  39.855999
2021-06-03 18:50:30,868 train_loss 1.595413
2021-06-03 18:50:49,162 valid_acc  39.539997
2021-06-03 18:50:49,162 valid_loss 1.604615
