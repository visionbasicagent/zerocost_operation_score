2021-06-03 19:07:00,861 args = Namespace(arch_learning_rate=0.0003, arch_weight_decay=0.001, batch_size=64, ckpt_interval=20, cutout=False, cutout_length=16, cutout_prob=1.0, data='../data', dataset='cifar10', dev='proj', edge_decision='random', epochs=100, expid_tag='none', fast=False, gpu='auto', grad_clip=5, init_channels=16, layers=8, learning_rate=0.025, learning_rate_min=0.001, log_tag='', method='darts-proj', model_path='saved_models', momentum=0.9, proj_crit='acc', proj_intv=5, report_freq=50, resume_epoch=100, resume_expid='search-darts-201-3', save='../experiments/nasbench201/search-darts-201-3', search_space='nas-bench-201', seed=3, train_portion=0.5, weight_decay=0.0003)
2021-06-03 19:07:00,861 gpu device = 0
2021-06-03 19:07:14,558 param size = 1.686106MB
2021-06-03 19:07:15,552 loading checkpoint from darts-proj-201
2021-06-03 19:07:15,552 => loading checkpoint '../experiments/nasbench201/search-darts-201-3/checkpoint_100.pth.tar'
2021-06-03 19:07:15,966 => loaded checkpoint '../experiments/nasbench201/search-darts-201-3/checkpoint_100.pth.tar' (epoch 99)
2021-06-03 19:07:28,808 tensor([[0.0789, 0.7100, 0.0722, 0.0915, 0.0473],
        [0.0567, 0.7817, 0.0574, 0.0646, 0.0396],
        [0.2846, 0.5514, 0.0440, 0.0557, 0.0642],
        [0.0255, 0.7900, 0.0523, 0.1085, 0.0237],
        [0.0833, 0.6465, 0.1217, 0.0903, 0.0582],
        [0.1218, 0.7079, 0.0713, 0.0609, 0.0381]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:07:47,562 train_acc  95.931999
2021-06-03 19:07:47,562 train_loss 0.128209
2021-06-03 19:08:05,799 valid_acc  86.671997
2021-06-03 19:08:05,799 valid_loss 0.416101
2021-06-03 19:08:05,802 epoch 0
2021-06-03 19:08:05,802 project
2021-06-03 19:08:26,055 valid_acc 85.655998
2021-06-03 19:08:26,056 valid_loss 0.446072
2021-06-03 19:08:46,567 valid_acc 15.115999
2021-06-03 19:08:46,567 valid_loss 5.772822
2021-06-03 19:09:06,607 valid_acc 74.863998
2021-06-03 19:09:06,608 valid_loss 0.785953
2021-06-03 19:09:26,512 valid_acc 53.591999
2021-06-03 19:09:26,513 valid_loss 1.627195
2021-06-03 19:09:46,848 valid_acc 85.487999
2021-06-03 19:09:46,849 valid_loss 0.446595
2021-06-03 19:10:07,245 valid_acc 86.035995
2021-06-03 19:10:07,246 valid_loss 0.436416
2021-06-03 19:10:27,283 valid_acc 33.236000
2021-06-03 19:10:27,283 valid_loss 3.347618
2021-06-03 19:10:47,638 valid_acc 83.236000
2021-06-03 19:10:47,638 valid_loss 0.516568
2021-06-03 19:11:07,872 valid_acc 80.731995
2021-06-03 19:11:07,872 valid_loss 0.600309
2021-06-03 19:11:28,168 valid_acc 85.916000
2021-06-03 19:11:28,168 valid_loss 0.444904
2021-06-03 19:11:49,249 valid_acc 86.175995
2021-06-03 19:11:49,249 valid_loss 0.435474
2021-06-03 19:12:09,369 valid_acc 78.147995
2021-06-03 19:12:09,369 valid_loss 0.771024
2021-06-03 19:12:29,277 valid_acc 84.495995
2021-06-03 19:12:29,277 valid_loss 0.480292
2021-06-03 19:12:49,486 valid_acc 82.723999
2021-06-03 19:12:49,486 valid_loss 0.543287
2021-06-03 19:13:09,381 valid_acc 85.715996
2021-06-03 19:13:09,381 valid_loss 0.437654
2021-06-03 19:13:29,788 valid_acc 85.680000
2021-06-03 19:13:29,788 valid_loss 0.443809
2021-06-03 19:13:50,009 valid_acc 11.455999
2021-06-03 19:13:50,009 valid_loss 6.060527
2021-06-03 19:14:10,270 valid_acc 82.643997
2021-06-03 19:14:10,270 valid_loss 0.536631
2021-06-03 19:14:30,272 valid_acc 61.115997
2021-06-03 19:14:30,272 valid_loss 1.232612
2021-06-03 19:14:50,257 valid_acc 85.875999
2021-06-03 19:14:50,258 valid_loss 0.436205
2021-06-03 19:15:10,364 valid_acc 85.727997
2021-06-03 19:15:10,364 valid_loss 0.439748
2021-06-03 19:15:30,311 valid_acc 64.851997
2021-06-03 19:15:30,311 valid_loss 1.400286
2021-06-03 19:15:50,499 valid_acc 69.395996
2021-06-03 19:15:50,499 valid_loss 0.951033
2021-06-03 19:16:10,589 valid_acc 67.844002
2021-06-03 19:16:10,589 valid_loss 1.036816
2021-06-03 19:16:30,899 valid_acc 85.751999
2021-06-03 19:16:30,899 valid_loss 0.441484
2021-06-03 19:16:51,453 valid_acc 85.783997
2021-06-03 19:16:51,453 valid_loss 0.438372
2021-06-03 19:17:11,782 valid_acc 25.427999
2021-06-03 19:17:11,783 valid_loss 4.400249
2021-06-03 19:17:31,807 valid_acc 78.959999
2021-06-03 19:17:31,807 valid_loss 0.657927
2021-06-03 19:17:52,071 valid_acc 75.995995
2021-06-03 19:17:52,071 valid_loss 0.757486
2021-06-03 19:18:12,259 valid_acc 85.835999
2021-06-03 19:18:12,259 valid_loss 0.439760
2021-06-03 19:19:53,831 best opid 1
2021-06-03 19:19:53,831 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0567, 0.7817, 0.0574, 0.0646, 0.0396],
        [0.2846, 0.5514, 0.0440, 0.0557, 0.0642],
        [0.0255, 0.7900, 0.0523, 0.1085, 0.0237],
        [0.0833, 0.6465, 0.1217, 0.0903, 0.0582],
        [0.1218, 0.7079, 0.0713, 0.0609, 0.0381]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:19:54,331 train 000 2.605195e+00 17.187500 75.000000
2021-06-03 19:20:10,151 train 050 1.781990e+00 36.305149 86.305153
2021-06-03 19:20:26,610 train 100 1.662605e+00 40.176361 88.814972
2021-06-03 19:20:42,517 train 150 1.570171e+00 43.584438 90.438744
2021-06-03 19:20:58,409 train 200 1.485925e+00 46.564053 91.487869
2021-06-03 19:21:14,891 train 250 1.401073e+00 49.713646 92.455185
2021-06-03 19:21:30,878 train 300 1.323875e+00 52.652615 93.277611
2021-06-03 19:21:47,271 train 350 1.258333e+00 55.252850 93.839027
2021-06-03 19:22:00,353 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0706, 0.7450, 0.0677, 0.0758, 0.0409],
        [0.3501, 0.4851, 0.0469, 0.0589, 0.0590],
        [0.0309, 0.7684, 0.0581, 0.1173, 0.0253],
        [0.1053, 0.6135, 0.1288, 0.0936, 0.0588],
        [0.1538, 0.6573, 0.0812, 0.0695, 0.0381]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:22:18,597 train_acc  73.096001
2021-06-03 19:22:18,598 train_loss 0.767104
2021-06-03 19:22:37,216 valid_acc  71.031998
2021-06-03 19:22:37,216 valid_loss 0.831952
2021-06-03 19:22:37,217 epoch 1
2021-06-03 19:22:37,603 train 000 1.210334e+00 57.045963 94.274658
2021-06-03 19:22:53,540 train 050 1.157482e+00 58.983162 94.678749
2021-06-03 19:23:09,968 train 100 1.118643e+00 60.399185 95.035599
2021-06-03 19:23:26,034 train 150 1.083926e+00 61.651859 95.349648
2021-06-03 19:23:43,939 train 200 1.048989e+00 62.951618 95.634377
2021-06-03 19:24:01,203 train 250 1.016570e+00 64.087761 95.872292
2021-06-03 19:24:17,298 train 300 9.887508e-01 65.098053 96.087112
2021-06-03 19:24:33,907 train 350 9.670089e-01 65.921539 96.254005
2021-06-03 19:24:47,081 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0823, 0.7183, 0.0741, 0.0843, 0.0408],
        [0.3922, 0.4437, 0.0484, 0.0616, 0.0541],
        [0.0356, 0.7524, 0.0621, 0.1237, 0.0262],
        [0.1222, 0.5852, 0.1375, 0.0977, 0.0574],
        [0.1781, 0.6191, 0.0887, 0.0773, 0.0368]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:25:06,177 train_acc  79.755997
2021-06-03 19:25:06,177 train_loss 0.586431
2021-06-03 19:25:25,188 valid_acc  76.839996
2021-06-03 19:25:25,188 valid_loss 0.690084
2021-06-03 19:25:25,188 epoch 2
2021-06-03 19:25:25,538 train 000 9.487427e-01 66.624725 96.378639
2021-06-03 19:25:41,449 train 050 9.284022e-01 67.377586 96.522980
2021-06-03 19:25:57,917 train 100 9.070105e-01 68.153160 96.684608
2021-06-03 19:26:13,818 train 150 8.883484e-01 68.840508 96.802086
2021-06-03 19:26:29,808 train 200 8.711112e-01 69.461060 96.909195
2021-06-03 19:26:46,319 train 250 8.562340e-01 70.015442 97.005936
2021-06-03 19:27:02,277 train 300 8.436033e-01 70.478172 97.083626
2021-06-03 19:27:18,931 train 350 8.297538e-01 70.959373 97.190331
2021-06-03 19:27:31,880 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0901, 0.7038, 0.0769, 0.0885, 0.0407],
        [0.4180, 0.4208, 0.0482, 0.0616, 0.0513],
        [0.0391, 0.7373, 0.0659, 0.1311, 0.0266],
        [0.1334, 0.5695, 0.1422, 0.0988, 0.0561],
        [0.1952, 0.5945, 0.0930, 0.0816, 0.0357]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:27:51,255 train_acc  83.715996
2021-06-03 19:27:51,255 train_loss 0.459771
2021-06-03 19:28:10,140 valid_acc  80.003998
2021-06-03 19:28:10,140 valid_loss 0.587897
2021-06-03 19:28:10,140 epoch 3
2021-06-03 19:28:10,504 train 000 8.186287e-01 71.365768 97.261009
2021-06-03 19:28:26,431 train 050 8.043267e-01 71.846573 97.348717
2021-06-03 19:28:42,957 train 100 7.910119e-01 72.311699 97.418488
2021-06-03 19:28:58,941 train 150 7.803999e-01 72.675522 97.484177
2021-06-03 19:29:14,909 train 200 7.695094e-01 73.064056 97.547348
2021-06-03 19:29:31,514 train 250 7.604045e-01 73.380264 97.615967
2021-06-03 19:29:47,491 train 300 7.517080e-01 73.679237 97.669312
2021-06-03 19:30:04,040 train 350 7.430074e-01 73.986298 97.720184
2021-06-03 19:30:16,954 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0949, 0.6938, 0.0790, 0.0924, 0.0399],
        [0.4329, 0.4079, 0.0483, 0.0618, 0.0490],
        [0.0411, 0.7308, 0.0674, 0.1342, 0.0265],
        [0.1405, 0.5657, 0.1409, 0.0978, 0.0551],
        [0.2047, 0.5824, 0.0945, 0.0836, 0.0348]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:30:35,731 train_acc  85.556000
2021-06-03 19:30:35,731 train_loss 0.415660
2021-06-03 19:30:54,299 valid_acc  81.667999
2021-06-03 19:30:54,299 valid_loss 0.544137
2021-06-03 19:30:54,300 epoch 4
2021-06-03 19:30:54,648 train 000 7.366087e-01 74.208504 97.756439
2021-06-03 19:31:10,612 train 050 7.278670e-01 74.502243 97.801750
2021-06-03 19:31:27,120 train 100 7.193897e-01 74.806511 97.849037
2021-06-03 19:31:42,971 train 150 7.109607e-01 75.103043 97.897217
2021-06-03 19:31:59,000 train 200 7.032625e-01 75.388962 97.940880
2021-06-03 19:32:15,491 train 250 6.959739e-01 75.658257 97.979561
2021-06-03 19:32:31,600 train 300 6.887474e-01 75.904716 98.021194
2021-06-03 19:32:48,106 train 350 6.825448e-01 76.121147 98.056580
2021-06-03 19:33:00,966 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0997, 0.6834, 0.0810, 0.0964, 0.0395],
        [0.4480, 0.3950, 0.0480, 0.0618, 0.0472],
        [0.0431, 0.7241, 0.0690, 0.1371, 0.0266],
        [0.1469, 0.5593, 0.1419, 0.0978, 0.0541],
        [0.2145, 0.5698, 0.0962, 0.0855, 0.0341]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:33:19,861 train_acc  86.192001
2021-06-03 19:33:19,861 train_loss 0.398273
2021-06-03 19:33:38,765 valid_acc  81.736000
2021-06-03 19:33:38,765 valid_loss 0.539889
2021-06-03 19:33:38,765 epoch 5
2021-06-03 19:33:38,765 project
2021-06-03 19:33:59,643 valid_acc 81.180000
2021-06-03 19:33:59,644 valid_loss 0.561820
2021-06-03 19:34:20,239 valid_acc 47.119999
2021-06-03 19:34:20,239 valid_loss 2.337439
2021-06-03 19:34:40,825 valid_acc 76.124001
2021-06-03 19:34:40,825 valid_loss 0.707570
2021-06-03 19:35:01,399 valid_acc 68.519997
2021-06-03 19:35:01,399 valid_loss 0.947320
2021-06-03 19:35:22,102 valid_acc 81.379997
2021-06-03 19:35:22,102 valid_loss 0.555434
2021-06-03 19:35:42,709 valid_acc 81.047997
2021-06-03 19:35:42,709 valid_loss 0.557524
2021-06-03 19:36:03,577 valid_acc 72.832001
2021-06-03 19:36:03,577 valid_loss 0.944145
2021-06-03 19:36:24,098 valid_acc 79.320000
2021-06-03 19:36:24,098 valid_loss 0.608628
2021-06-03 19:36:44,710 valid_acc 77.251999
2021-06-03 19:36:44,710 valid_loss 0.673567
2021-06-03 19:37:05,495 valid_acc 81.540001
2021-06-03 19:37:05,495 valid_loss 0.552333
2021-06-03 19:37:26,099 valid_acc 81.251999
2021-06-03 19:37:26,099 valid_loss 0.558147
2021-06-03 19:37:46,586 valid_acc 14.252000
2021-06-03 19:37:46,587 valid_loss 5.612372
2021-06-03 19:38:07,542 valid_acc 77.531998
2021-06-03 19:38:07,542 valid_loss 0.672798
2021-06-03 19:38:28,332 valid_acc 46.023998
2021-06-03 19:38:28,332 valid_loss 1.671994
2021-06-03 19:38:49,322 valid_acc 81.439995
2021-06-03 19:38:49,322 valid_loss 0.551689
2021-06-03 19:39:09,969 valid_acc 81.068001
2021-06-03 19:39:09,969 valid_loss 0.566812
2021-06-03 19:39:30,400 valid_acc 23.320000
2021-06-03 19:39:30,400 valid_loss 4.177429
2021-06-03 19:39:51,062 valid_acc 64.487999
2021-06-03 19:39:51,062 valid_loss 1.050072
2021-06-03 19:40:11,657 valid_acc 60.747997
2021-06-03 19:40:11,657 valid_loss 1.191279
2021-06-03 19:40:32,741 valid_acc 81.388000
2021-06-03 19:40:32,741 valid_loss 0.552742
2021-06-03 19:40:53,144 valid_acc 80.916000
2021-06-03 19:40:53,144 valid_loss 0.562321
2021-06-03 19:41:13,484 valid_acc 34.980000
2021-06-03 19:41:13,484 valid_loss 3.260445
2021-06-03 19:41:34,339 valid_acc 70.451996
2021-06-03 19:41:34,339 valid_loss 0.878227
2021-06-03 19:41:55,085 valid_acc 62.307999
2021-06-03 19:41:55,085 valid_loss 1.162346
2021-06-03 19:42:15,653 valid_acc 81.327995
2021-06-03 19:42:15,653 valid_loss 0.556939
2021-06-03 19:43:59,547 best opid 1
2021-06-03 19:43:59,548 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4480, 0.3950, 0.0480, 0.0618, 0.0472],
        [0.0431, 0.7241, 0.0690, 0.1371, 0.0266],
        [0.1469, 0.5593, 0.1419, 0.0978, 0.0541],
        [0.2145, 0.5698, 0.0962, 0.0855, 0.0341]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:43:59,906 train 000 6.786730e-01 76.262558 98.072189
2021-06-03 19:44:16,361 train 050 6.874369e-01 75.955841 98.029839
2021-06-03 19:44:32,235 train 100 6.877923e-01 75.925728 98.046616
2021-06-03 19:44:48,720 train 150 6.881509e-01 75.935661 98.051445
2021-06-03 19:45:04,630 train 200 6.864185e-01 76.008240 98.069839
2021-06-03 19:45:20,478 train 250 6.842254e-01 76.071854 98.089523
2021-06-03 19:45:36,987 train 300 6.821317e-01 76.158981 98.104172
2021-06-03 19:45:52,851 train 350 6.803802e-01 76.215210 98.126320
2021-06-03 19:46:05,747 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4708, 0.3602, 0.0543, 0.0717, 0.0430],
        [0.0492, 0.7013, 0.0750, 0.1470, 0.0275],
        [0.1661, 0.5300, 0.1482, 0.1031, 0.0525],
        [0.2485, 0.5315, 0.0996, 0.0874, 0.0329]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:46:24,095 train_acc  79.391998
2021-06-03 19:46:24,095 train_loss 0.598564
2021-06-03 19:46:42,699 valid_acc  76.264000
2021-06-03 19:46:42,699 valid_loss 0.710118
2021-06-03 19:46:42,699 epoch 6
2021-06-03 19:46:43,042 train 000 6.787245e-01 76.285454 98.136131
2021-06-03 19:46:59,480 train 050 6.764738e-01 76.356483 98.158737
2021-06-03 19:47:15,550 train 100 6.733955e-01 76.462959 98.177216
2021-06-03 19:47:32,143 train 150 6.713160e-01 76.540733 98.193703
2021-06-03 19:47:48,212 train 200 6.691866e-01 76.611160 98.206482
2021-06-03 19:48:04,220 train 250 6.666185e-01 76.698746 98.221771
2021-06-03 19:48:20,673 train 300 6.642032e-01 76.784195 98.239433
2021-06-03 19:48:36,607 train 350 6.616324e-01 76.863579 98.257607
2021-06-03 19:48:49,451 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4799, 0.3447, 0.0572, 0.0769, 0.0413],
        [0.0526, 0.6897, 0.0788, 0.1509, 0.0280],
        [0.1770, 0.5173, 0.1492, 0.1046, 0.0519],
        [0.2653, 0.5115, 0.1020, 0.0889, 0.0322]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:49:07,721 train_acc  83.115997
2021-06-03 19:49:07,721 train_loss 0.485974
2021-06-03 19:49:25,874 valid_acc  79.231995
2021-06-03 19:49:25,874 valid_loss 0.609331
2021-06-03 19:49:25,874 epoch 7
2021-06-03 19:49:26,231 train 000 6.594666e-01 76.933006 98.268631
2021-06-03 19:49:42,477 train 050 6.566071e-01 77.035179 98.283440
2021-06-03 19:49:58,218 train 100 6.538305e-01 77.131554 98.301041
2021-06-03 19:50:14,458 train 150 6.508605e-01 77.236496 98.319649
2021-06-03 19:50:30,233 train 200 6.478959e-01 77.341591 98.339760
2021-06-03 19:50:45,794 train 250 6.453320e-01 77.436882 98.350815
2021-06-03 19:51:01,899 train 300 6.425673e-01 77.541901 98.362022
2021-06-03 19:51:17,544 train 350 6.405448e-01 77.617188 98.374893
2021-06-03 19:51:30,213 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4824, 0.3372, 0.0592, 0.0812, 0.0399],
        [0.0543, 0.6864, 0.0790, 0.1524, 0.0279],
        [0.1830, 0.5139, 0.1482, 0.1039, 0.0510],
        [0.2745, 0.5029, 0.1017, 0.0895, 0.0314]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:51:48,097 train_acc  85.112000
2021-06-03 19:51:48,097 train_loss 0.427515
2021-06-03 19:52:06,044 valid_acc  80.867996
2021-06-03 19:52:06,044 valid_loss 0.558081
2021-06-03 19:52:06,044 epoch 8
2021-06-03 19:52:06,398 train 000 6.386696e-01 77.686142 98.384514
2021-06-03 19:52:22,669 train 050 6.354475e-01 77.797836 98.402565
2021-06-03 19:52:38,406 train 100 6.330301e-01 77.873138 98.417641
2021-06-03 19:52:54,606 train 150 6.308101e-01 77.958069 98.429398
2021-06-03 19:53:10,337 train 200 6.284400e-01 78.037148 98.443611
2021-06-03 19:53:26,232 train 250 6.260490e-01 78.129166 98.453239
2021-06-03 19:53:42,635 train 300 6.235938e-01 78.202988 98.468513
2021-06-03 19:53:58,399 train 350 6.209247e-01 78.302109 98.478409
2021-06-03 19:54:11,286 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4848, 0.3298, 0.0613, 0.0854, 0.0387],
        [0.0560, 0.6817, 0.0791, 0.1554, 0.0278],
        [0.1897, 0.5107, 0.1465, 0.1032, 0.0500],
        [0.2845, 0.4946, 0.1009, 0.0895, 0.0306]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:54:29,306 train_acc  85.579994
2021-06-03 19:54:29,306 train_loss 0.416035
2021-06-03 19:54:47,390 valid_acc  81.323997
2021-06-03 19:54:47,391 valid_loss 0.558018
2021-06-03 19:54:47,391 epoch 9
2021-06-03 19:54:47,743 train 000 6.190537e-01 78.367928 98.490204
2021-06-03 19:55:04,107 train 050 6.161171e-01 78.476234 98.502609
2021-06-03 19:55:19,830 train 100 6.136097e-01 78.559082 98.516403
2021-06-03 19:55:36,384 train 150 6.111833e-01 78.635406 98.529381
2021-06-03 19:55:52,272 train 200 6.089117e-01 78.714302 98.539917
2021-06-03 19:56:08,143 train 250 6.068901e-01 78.788620 98.548515
2021-06-03 19:56:24,561 train 300 6.047981e-01 78.865082 98.559349
2021-06-03 19:56:40,498 train 350 6.025975e-01 78.946030 98.570702
2021-06-03 19:56:53,387 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4847, 0.3242, 0.0630, 0.0901, 0.0381],
        [0.0574, 0.6769, 0.0802, 0.1575, 0.0280],
        [0.1951, 0.5082, 0.1447, 0.1023, 0.0497],
        [0.2914, 0.4877, 0.1008, 0.0898, 0.0303]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 19:57:11,667 train_acc  85.959999
2021-06-03 19:57:11,667 train_loss 0.405822
2021-06-03 19:57:30,082 valid_acc  81.687996
2021-06-03 19:57:30,082 valid_loss 0.544755
2021-06-03 19:57:30,083 epoch 10
2021-06-03 19:57:30,083 project
2021-06-03 19:57:50,451 valid_acc 81.043999
2021-06-03 19:57:50,451 valid_loss 0.553624
2021-06-03 19:58:10,975 valid_acc 77.683998
2021-06-03 19:58:10,975 valid_loss 0.707787
2021-06-03 19:58:31,537 valid_acc 77.959999
2021-06-03 19:58:31,537 valid_loss 0.638157
2021-06-03 19:58:52,174 valid_acc 72.447998
2021-06-03 19:58:52,174 valid_loss 0.810847
2021-06-03 19:59:13,083 valid_acc 81.047997
2021-06-03 19:59:13,083 valid_loss 0.554085
2021-06-03 19:59:33,167 valid_acc 81.431999
2021-06-03 19:59:33,167 valid_loss 0.545551
2021-06-03 19:59:53,664 valid_acc 14.704000
2021-06-03 19:59:53,665 valid_loss 5.206793
2021-06-03 20:00:13,842 valid_acc 74.931999
2021-06-03 20:00:13,843 valid_loss 0.732332
2021-06-03 20:00:34,879 valid_acc 42.975998
2021-06-03 20:00:34,880 valid_loss 1.759841
2021-06-03 20:00:56,399 valid_acc 81.375999
2021-06-03 20:00:56,400 valid_loss 0.546910
2021-06-03 20:01:17,139 valid_acc 81.311996
2021-06-03 20:01:17,139 valid_loss 0.549379
2021-06-03 20:01:37,564 valid_acc 26.844000
2021-06-03 20:01:37,565 valid_loss 3.628947
2021-06-03 20:01:57,900 valid_acc 63.143997
2021-06-03 20:01:57,900 valid_loss 1.100877
2021-06-03 20:02:18,129 valid_acc 63.571999
2021-06-03 20:02:18,129 valid_loss 1.107416
2021-06-03 20:02:38,509 valid_acc 81.403999
2021-06-03 20:02:38,510 valid_loss 0.553631
2021-06-03 20:02:58,769 valid_acc 81.227997
2021-06-03 20:02:58,769 valid_loss 0.553385
2021-06-03 20:03:18,970 valid_acc 23.528000
2021-06-03 20:03:18,970 valid_loss 4.261716
2021-06-03 20:03:39,259 valid_acc 69.171997
2021-06-03 20:03:39,259 valid_loss 0.906278
2021-06-03 20:03:59,885 valid_acc 59.983997
2021-06-03 20:03:59,885 valid_loss 1.263343
2021-06-03 20:04:20,204 valid_acc 81.063995
2021-06-03 20:04:20,205 valid_loss 0.554838
2021-06-03 20:06:01,432 best opid 3
2021-06-03 20:06:01,432 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0574, 0.6769, 0.0802, 0.1575, 0.0280],
        [0.1951, 0.5082, 0.1447, 0.1023, 0.0497],
        [0.2914, 0.4877, 0.1008, 0.0898, 0.0303]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:06:01,780 train 000 6.017473e-01 78.990181 98.573570
2021-06-03 20:06:17,510 train 050 6.267043e-01 78.366837 98.350731
2021-06-03 20:06:33,205 train 100 6.374058e-01 77.970009 98.276176
2021-06-03 20:06:49,489 train 150 6.438544e-01 77.733917 98.240417
2021-06-03 20:07:05,189 train 200 6.481194e-01 77.576233 98.222275
2021-06-03 20:07:21,374 train 250 6.510781e-01 77.480232 98.212837
2021-06-03 20:07:37,218 train 300 6.527950e-01 77.421043 98.211044
2021-06-03 20:07:53,520 train 350 6.538651e-01 77.375359 98.213341
2021-06-03 20:08:05,790 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0548, 0.6789, 0.0794, 0.1598, 0.0271],
        [0.1869, 0.5233, 0.1407, 0.0999, 0.0492],
        [0.2930, 0.4818, 0.1035, 0.0926, 0.0291]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:08:23,678 train_acc  75.916000
2021-06-03 20:08:23,678 train_loss 0.690142
2021-06-03 20:08:42,096 valid_acc  74.075996
2021-06-03 20:08:42,096 valid_loss 0.759586
2021-06-03 20:08:42,096 epoch 11
2021-06-03 20:08:42,449 train 000 6.541023e-01 77.372177 98.216774
2021-06-03 20:08:58,152 train 050 6.543549e-01 77.362144 98.223274
2021-06-03 20:09:13,804 train 100 6.546118e-01 77.351990 98.225700
2021-06-03 20:09:30,045 train 150 6.540211e-01 77.371216 98.236168
2021-06-03 20:09:45,766 train 200 6.530516e-01 77.403915 98.245354
2021-06-03 20:10:02,011 train 250 6.520404e-01 77.434860 98.255371
2021-06-03 20:10:17,726 train 300 6.508192e-01 77.479744 98.262108
2021-06-03 20:10:34,084 train 350 6.498805e-01 77.504173 98.275085
2021-06-03 20:10:46,270 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0552, 0.6723, 0.0803, 0.1647, 0.0275],
        [0.1874, 0.5221, 0.1409, 0.1000, 0.0496],
        [0.3024, 0.4661, 0.1068, 0.0959, 0.0288]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:11:04,495 train_acc  81.087997
2021-06-03 20:11:04,495 train_loss 0.539930
2021-06-03 20:11:22,125 valid_acc  77.664001
2021-06-03 20:11:22,125 valid_loss 0.647518
2021-06-03 20:11:22,125 epoch 12
2021-06-03 20:11:22,461 train 000 6.489319e-01 77.539459 98.280029
2021-06-03 20:11:38,745 train 050 6.473947e-01 77.595428 98.289276
2021-06-03 20:11:55,302 train 100 6.459765e-01 77.645988 98.297676
2021-06-03 20:12:10,966 train 150 6.445390e-01 77.697121 98.307846
2021-06-03 20:12:26,813 train 200 6.430875e-01 77.750397 98.318443
2021-06-03 20:12:43,036 train 250 6.414014e-01 77.807976 98.327553
2021-06-03 20:12:58,719 train 300 6.396842e-01 77.870667 98.338989
2021-06-03 20:13:14,806 train 350 6.379176e-01 77.934898 98.350517
2021-06-03 20:13:27,034 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0552, 0.6685, 0.0807, 0.1679, 0.0277],
        [0.1870, 0.5234, 0.1400, 0.0999, 0.0497],
        [0.3087, 0.4552, 0.1090, 0.0984, 0.0286]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:13:45,608 train_acc  86.307999
2021-06-03 20:13:45,608 train_loss 0.395655
2021-06-03 20:14:03,513 valid_acc  82.031998
2021-06-03 20:14:03,514 valid_loss 0.524580
2021-06-03 20:14:03,514 epoch 13
2021-06-03 20:14:03,871 train 000 6.365152e-01 77.984329 98.360931
2021-06-03 20:14:19,545 train 050 6.346821e-01 78.046028 98.372047
2021-06-03 20:14:35,786 train 100 6.328061e-01 78.105621 98.383240
2021-06-03 20:14:51,431 train 150 6.312026e-01 78.161980 98.394211
2021-06-03 20:15:07,175 train 200 6.293016e-01 78.227631 98.403206
2021-06-03 20:15:23,368 train 250 6.275213e-01 78.286774 98.414078
2021-06-03 20:15:39,157 train 300 6.255952e-01 78.351501 98.422142
2021-06-03 20:15:55,387 train 350 6.239609e-01 78.409851 98.429764
2021-06-03 20:16:07,638 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0550, 0.6677, 0.0808, 0.1687, 0.0278],
        [0.1861, 0.5254, 0.1396, 0.0995, 0.0495],
        [0.3156, 0.4436, 0.1115, 0.1013, 0.0281]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:16:25,506 train_acc  84.979996
2021-06-03 20:16:25,507 train_loss 0.425970
2021-06-03 20:16:43,206 valid_acc  80.571999
2021-06-03 20:16:43,207 valid_loss 0.576009
2021-06-03 20:16:43,207 epoch 14
2021-06-03 20:16:43,543 train 000 6.224792e-01 78.461937 98.437431
2021-06-03 20:16:59,425 train 050 6.204946e-01 78.529083 98.446770
2021-06-03 20:17:15,579 train 100 6.185370e-01 78.596153 98.457062
2021-06-03 20:17:31,148 train 150 6.167685e-01 78.651741 98.466347
2021-06-03 20:17:46,753 train 200 6.150040e-01 78.710487 98.474915
2021-06-03 20:18:03,131 train 250 6.133692e-01 78.767380 98.481140
2021-06-03 20:18:18,858 train 300 6.113078e-01 78.838173 98.492409
2021-06-03 20:18:35,137 train 350 6.096210e-01 78.892990 98.501595
2021-06-03 20:18:47,972 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0539, 0.6707, 0.0801, 0.1676, 0.0277],
        [0.1821, 0.5327, 0.1370, 0.0988, 0.0494],
        [0.3169, 0.4405, 0.1124, 0.1024, 0.0278]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:19:06,176 train_acc  87.911995
2021-06-03 20:19:06,177 train_loss 0.346336
2021-06-03 20:19:24,102 valid_acc  83.159996
2021-06-03 20:19:24,103 valid_loss 0.499770
2021-06-03 20:19:24,103 epoch 15
2021-06-03 20:19:24,103 project
2021-06-03 20:19:43,916 valid_acc 82.695999
2021-06-03 20:19:43,917 valid_loss 0.512844
2021-06-03 20:20:04,538 valid_acc 14.179999
2021-06-03 20:20:04,538 valid_loss 5.709800
2021-06-03 20:20:26,262 valid_acc 81.248001
2021-06-03 20:20:26,262 valid_loss 0.555005
2021-06-03 20:20:46,544 valid_acc 71.127998
2021-06-03 20:20:46,544 valid_loss 0.872345
2021-06-03 20:21:06,324 valid_acc 82.692001
2021-06-03 20:21:06,324 valid_loss 0.516525
2021-06-03 20:21:25,962 valid_acc 82.591995
2021-06-03 20:21:25,962 valid_loss 0.515040
2021-06-03 20:21:45,481 valid_acc 20.688000
2021-06-03 20:21:45,481 valid_loss 4.587638
2021-06-03 20:22:05,275 valid_acc 79.223999
2021-06-03 20:22:05,275 valid_loss 0.609960
2021-06-03 20:22:24,730 valid_acc 79.827995
2021-06-03 20:22:24,730 valid_loss 0.603716
2021-06-03 20:22:44,660 valid_acc 82.084000
2021-06-03 20:22:44,660 valid_loss 0.530626
2021-06-03 20:23:04,338 valid_acc 82.900002
2021-06-03 20:23:04,338 valid_loss 0.509791
2021-06-03 20:23:24,500 valid_acc 38.079998
2021-06-03 20:23:24,500 valid_loss 3.096861
2021-06-03 20:23:44,587 valid_acc 78.708000
2021-06-03 20:23:44,588 valid_loss 0.624042
2021-06-03 20:24:04,878 valid_acc 75.523994
2021-06-03 20:24:04,878 valid_loss 0.718697
2021-06-03 20:24:24,690 valid_acc 82.900002
2021-06-03 20:24:24,691 valid_loss 0.512104
2021-06-03 20:26:04,004 best opid 1
2021-06-03 20:26:04,004 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1821, 0.5327, 0.1370, 0.0988, 0.0494],
        [0.3169, 0.4405, 0.1124, 0.1024, 0.0278]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:26:04,326 train 000 6.082603e-01 78.938263 98.506660
2021-06-03 20:26:20,071 train 050 6.123122e-01 78.802635 98.475929
2021-06-03 20:26:36,749 train 100 6.128097e-01 78.794853 98.477707
2021-06-03 20:26:52,665 train 150 6.125821e-01 78.800201 98.479454
2021-06-03 20:27:08,637 train 200 6.118938e-01 78.824020 98.487358
2021-06-03 20:27:25,142 train 250 6.111450e-01 78.853592 98.493599
2021-06-03 20:27:41,085 train 300 6.104026e-01 78.874817 98.496948
2021-06-03 20:27:57,760 train 350 6.095608e-01 78.898468 98.504265
2021-06-03 20:28:10,701 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2019, 0.4906, 0.1493, 0.1081, 0.0501],
        [0.3440, 0.4005, 0.1185, 0.1094, 0.0277]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:28:29,160 train_acc  83.767998
2021-06-03 20:28:29,160 train_loss 0.476425
2021-06-03 20:28:48,003 valid_acc  80.099998
2021-06-03 20:28:48,003 valid_loss 0.586303
2021-06-03 20:28:48,003 epoch 16
2021-06-03 20:28:48,365 train 000 6.089342e-01 78.920372 98.508987
2021-06-03 20:29:04,381 train 050 6.078138e-01 78.957954 98.514366
2021-06-03 20:29:20,924 train 100 6.068228e-01 78.988052 98.519920
2021-06-03 20:29:36,970 train 150 6.057934e-01 79.024277 98.524643
2021-06-03 20:29:52,917 train 200 6.051218e-01 79.048546 98.528572
2021-06-03 20:30:09,441 train 250 6.042282e-01 79.077499 98.536285
2021-06-03 20:30:25,325 train 300 6.031972e-01 79.115311 98.541969
2021-06-03 20:30:41,834 train 350 6.019568e-01 79.155388 98.547806
2021-06-03 20:30:54,761 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2087, 0.4789, 0.1514, 0.1106, 0.0503],
        [0.3558, 0.3867, 0.1181, 0.1118, 0.0276]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:31:13,595 train_acc  84.799995
2021-06-03 20:31:13,596 train_loss 0.433156
2021-06-03 20:31:32,256 valid_acc  81.079994
2021-06-03 20:31:32,256 valid_loss 0.556534
2021-06-03 20:31:32,256 epoch 17
2021-06-03 20:31:32,633 train 000 6.012618e-01 79.179138 98.551514
2021-06-03 20:31:48,824 train 050 6.002334e-01 79.212120 98.557899
2021-06-03 20:32:05,395 train 100 5.990112e-01 79.255280 98.565117
2021-06-03 20:32:21,422 train 150 5.980200e-01 79.287682 98.568779
2021-06-03 20:32:37,441 train 200 5.965790e-01 79.337875 98.576500
2021-06-03 20:32:53,986 train 250 5.957004e-01 79.370567 98.582062
2021-06-03 20:33:09,915 train 300 5.947556e-01 79.400314 98.588226
2021-06-03 20:33:26,353 train 350 5.936174e-01 79.439468 98.594307
2021-06-03 20:33:39,206 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2153, 0.4679, 0.1536, 0.1134, 0.0498],
        [0.3670, 0.3741, 0.1187, 0.1131, 0.0271]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:33:58,160 train_acc  85.759995
2021-06-03 20:33:58,160 train_loss 0.412252
2021-06-03 20:34:17,170 valid_acc  81.540001
2021-06-03 20:34:17,170 valid_loss 0.537096
2021-06-03 20:34:17,170 epoch 18
2021-06-03 20:34:17,520 train 000 5.927428e-01 79.467369 98.599533
2021-06-03 20:34:33,476 train 050 5.914088e-01 79.515907 98.605667
2021-06-03 20:34:49,884 train 100 5.901754e-01 79.562462 98.610191
2021-06-03 20:35:05,925 train 150 5.889606e-01 79.601616 98.617462
2021-06-03 20:35:21,783 train 200 5.878728e-01 79.640678 98.621849
2021-06-03 20:35:38,287 train 250 5.867721e-01 79.678116 98.626801
2021-06-03 20:35:54,294 train 300 5.857067e-01 79.714401 98.633812
2021-06-03 20:36:10,828 train 350 5.845535e-01 79.753380 98.639473
2021-06-03 20:36:23,730 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2198, 0.4618, 0.1540, 0.1152, 0.0492],
        [0.3763, 0.3651, 0.1182, 0.1136, 0.0267]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:36:42,688 train_acc  87.159996
2021-06-03 20:36:42,689 train_loss 0.371095
2021-06-03 20:37:01,524 valid_acc  82.591995
2021-06-03 20:37:01,524 valid_loss 0.512282
2021-06-03 20:37:01,524 epoch 19
2021-06-03 20:37:01,851 train 000 5.836318e-01 79.781883 98.644814
2021-06-03 20:37:17,883 train 050 5.823782e-01 79.826202 98.650322
2021-06-03 20:37:34,419 train 100 5.810764e-01 79.870773 98.655769
2021-06-03 20:37:50,353 train 150 5.799474e-01 79.911446 98.662994
2021-06-03 20:38:06,296 train 200 5.789135e-01 79.945847 98.668282
2021-06-03 20:38:22,686 train 250 5.776892e-01 79.986511 98.674713
2021-06-03 20:38:38,552 train 300 5.765374e-01 80.025253 98.679855
2021-06-03 20:38:54,793 train 350 5.754131e-01 80.061874 98.685326
2021-06-03 20:39:07,583 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2221, 0.4604, 0.1534, 0.1150, 0.0490],
        [0.3814, 0.3595, 0.1183, 0.1145, 0.0263]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:39:25,937 train_acc  85.731995
2021-06-03 20:39:25,938 train_loss 0.407463
2021-06-03 20:39:44,366 valid_acc  81.136002
2021-06-03 20:39:44,366 valid_loss 0.566135
2021-06-03 20:39:44,366 epoch 20
2021-06-03 20:39:44,366 project
2021-06-03 20:40:04,774 valid_acc 82.127998
2021-06-03 20:40:04,774 valid_loss 0.535256
2021-06-03 20:40:24,911 valid_acc 32.439999
2021-06-03 20:40:24,911 valid_loss 3.263428
2021-06-03 20:40:45,078 valid_acc 75.391998
2021-06-03 20:40:45,078 valid_loss 0.728846
2021-06-03 20:41:05,449 valid_acc 71.575996
2021-06-03 20:41:05,449 valid_loss 0.848561
2021-06-03 20:41:25,941 valid_acc 81.351997
2021-06-03 20:41:25,941 valid_loss 0.550715
2021-06-03 20:41:46,283 valid_acc 82.028000
2021-06-03 20:41:46,283 valid_loss 0.540290
2021-06-03 20:42:06,716 valid_acc 22.424000
2021-06-03 20:42:06,716 valid_loss 3.951607
2021-06-03 20:42:26,935 valid_acc 76.383995
2021-06-03 20:42:26,935 valid_loss 0.693270
2021-06-03 20:42:47,961 valid_acc 68.283997
2021-06-03 20:42:47,961 valid_loss 0.976603
2021-06-03 20:43:08,284 valid_acc 81.451996
2021-06-03 20:43:08,285 valid_loss 0.541031
2021-06-03 20:44:49,899 best opid 1
2021-06-03 20:44:49,899 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.3814, 0.3595, 0.1183, 0.1145, 0.0263]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:44:50,771 train 000 5.746911e-01 80.083946 98.686768
2021-06-03 20:45:06,580 train 050 5.817073e-01 79.825500 98.623192
2021-06-03 20:45:22,366 train 100 5.865222e-01 79.654228 98.591995
2021-06-03 20:45:38,679 train 150 5.906637e-01 79.503166 98.566116
2021-06-03 20:45:54,462 train 200 5.935272e-01 79.402138 98.552048
2021-06-03 20:46:10,713 train 250 5.957063e-01 79.333382 98.541458
2021-06-03 20:46:26,609 train 300 5.972548e-01 79.287033 98.536781
2021-06-03 20:46:42,595 train 350 5.984973e-01 79.247566 98.534637
2021-06-03 20:46:55,564 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4073, 0.3255, 0.1195, 0.1210, 0.0267]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:47:13,836 train_acc  72.739998
2021-06-03 20:47:13,837 train_loss 0.788902
2021-06-03 20:47:31,930 valid_acc  71.316002
2021-06-03 20:47:31,930 valid_loss 0.830865
2021-06-03 20:47:31,930 epoch 21
2021-06-03 20:47:32,822 train 000 5.992963e-01 79.225578 98.534279
2021-06-03 20:47:48,665 train 050 6.001193e-01 79.201118 98.534065
2021-06-03 20:48:04,640 train 100 6.008146e-01 79.182220 98.534241
2021-06-03 20:48:20,871 train 150 6.014883e-01 79.160561 98.532722
2021-06-03 20:48:36,882 train 200 6.020546e-01 79.143982 98.533272
2021-06-03 20:48:53,250 train 250 6.024171e-01 79.131493 98.533630
2021-06-03 20:49:08,956 train 300 6.026936e-01 79.125755 98.535088
2021-06-03 20:49:24,784 train 350 6.030197e-01 79.115524 98.536163
2021-06-03 20:49:37,866 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4238, 0.3038, 0.1196, 0.1257, 0.0272]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:49:56,216 train_acc  76.903999
2021-06-03 20:49:56,216 train_loss 0.665870
2021-06-03 20:50:14,243 valid_acc  74.771996
2021-06-03 20:50:14,243 valid_loss 0.727422
2021-06-03 20:50:14,243 epoch 22
2021-06-03 20:50:15,123 train 000 6.032182e-01 79.112976 98.536354
2021-06-03 20:50:30,960 train 050 6.033382e-01 79.112869 98.537407
2021-06-03 20:50:46,774 train 100 6.036491e-01 79.098381 98.539711
2021-06-03 20:51:03,062 train 150 6.038429e-01 79.090309 98.541267
2021-06-03 20:51:18,916 train 200 6.038076e-01 79.090332 98.544228
2021-06-03 20:51:35,317 train 250 6.036484e-01 79.096176 98.547157
2021-06-03 20:51:51,154 train 300 6.036778e-01 79.104073 98.547775
2021-06-03 20:52:07,065 train 350 6.038142e-01 79.101044 98.549255
2021-06-03 20:52:20,034 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4383, 0.2884, 0.1177, 0.1281, 0.0275]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:52:38,872 train_acc  79.428001
2021-06-03 20:52:38,872 train_loss 0.593211
2021-06-03 20:52:57,433 valid_acc  77.199997
2021-06-03 20:52:57,434 valid_loss 0.656820
2021-06-03 20:52:57,434 epoch 23
2021-06-03 20:52:58,314 train 000 6.037546e-01 79.105804 98.550949
2021-06-03 20:53:14,159 train 050 6.038713e-01 79.106430 98.550316
2021-06-03 20:53:30,129 train 100 6.035714e-01 79.115135 98.553825
2021-06-03 20:53:46,606 train 150 6.034356e-01 79.120148 98.557976
2021-06-03 20:54:02,621 train 200 6.034144e-01 79.121025 98.559364
2021-06-03 20:54:18,967 train 250 6.032307e-01 79.131874 98.560562
2021-06-03 20:54:35,012 train 300 6.031438e-01 79.134697 98.562927
2021-06-03 20:54:51,120 train 350 6.031007e-01 79.136314 98.563934
2021-06-03 20:55:04,114 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.4526, 0.2757, 0.1147, 0.1295, 0.0275]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2021-06-03 20:55:22,438 train_acc  80.815994
2021-06-03 20:55:22,439 train_loss 0.551978
2021-06-03 20:55:40,783 valid_acc  77.652000
2021-06-03 20:55:40,783 valid_loss 0.645701
2021-06-03 20:55:40,784 epoch 24
2021-06-03 20:55:40,784 project
2021-06-03 20:56:01,275 valid_acc 78.423996
2021-06-03 20:56:01,275 valid_loss 0.623246
2021-06-03 20:56:22,147 valid_acc 8.208000
2021-06-03 20:56:22,147 valid_loss 3.918259
2021-06-03 20:56:42,622 valid_acc 64.463997
2021-06-03 20:56:42,622 valid_loss 1.026730
2021-06-03 20:57:03,351 valid_acc 45.435997
2021-06-03 20:57:03,351 valid_loss 1.607236
2021-06-03 20:57:23,680 valid_acc 78.127998
2021-06-03 20:57:23,680 valid_loss 0.629936
2021-06-03 20:59:05,926 best opid 1
2021-06-03 20:59:05,927 tensor([[0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2021-06-03 20:59:06,272 train 000 6.031179e-01 79.140724 98.562653
2021-06-03 20:59:22,024 train 050 6.101710e-01 78.864311 98.475952
2021-06-03 20:59:38,243 train 100 6.160812e-01 78.629562 98.420357
2021-06-03 20:59:53,847 train 150 6.219490e-01 78.406631 98.365166
2021-06-03 21:00:09,983 train 200 6.273171e-01 78.190430 98.318222
2021-06-03 21:00:25,650 train 250 6.324808e-01 77.983780 98.276802
2021-06-03 21:00:41,931 train 300 6.375043e-01 77.784431 98.233383
2021-06-03 21:00:57,550 train 350 6.422462e-01 77.595650 98.196518
2021-06-03 21:01:10,254 tensor([[0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2021-06-03 21:01:28,088 train_acc  40.987999
2021-06-03 21:01:28,088 train_loss 1.544405
2021-06-03 21:01:46,137 valid_acc  40.647999
2021-06-03 21:01:46,137 valid_loss 1.557015
